{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08) 엘모(Embeddings from Language Model, ELMo).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPwDyyX7B6cFtt8Vll7R73H"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7RUxQItpM1t_"},"source":["## 08) 엘모(Embeddings from Language Model, ELMo)\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/elmo_DSHQjZD.png'>\r\n","\r\n","논문 링크 : https://aclweb.org/anthology/N18-1202\r\n","\r\n","ELMo(Embeddings from Language Model)는 2018년에 제안된 새로운 워드 임베딩 방법론이다. ELMo라는 이름은 세서미 스트리트라는 미국 인형극의 캐릭터 이름이기도 한데, 뒤에서 배우게 되는 BERT나 최근 마이크로소프트가 사용한 Big Bird라는 NLP 모델 또한 ELMo에 이어 세서미 스트리트의 캐릭터의 이름을 사용했다. ELMo는 Embeddings from Language Model의 약자이다. 해석하면 '언어 모델로 하는 임베딩'이다. ELMo의 가장 큰 특징은 **사전 훈련된 언어 모델(Pre-trained language model)**을 사용한다는 점이다. 이는 ELMo의 이름에 LM이 들어간 이유이다.\r\n","\r\n","```\r\n","현재 텐서플로우 2.0에서는 TF-Hub의 ELMo를 사용할 수 없습니다. 사용하려면 텐서플로우 버전을 1버전으로 낮추어야 합니다. Colab에서 실습하시는 것을 권장드립니다. Colab에서는 손쉽게 텐서플로우 버전을 1버전으로 설정할 수 있습니다. 아래 실습 내용을 참고하세요.\r\n","```\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"ZVALY8oVM6Dg"},"source":["### 1.ELMo(Embeddings from Language Model)\r\n","\r\n","Bank라는 단어를 생각해보자. Bank Account(은행 계좌)와 River Bank(강둑)에서의 Bank는 전혀 다른 의미를 가지는데, Word2Vec이나 GloVe 등으로 표현된 임베딩 벡터들은 이를 제대로 반영하지 못한다는 단점이 있다. 예를 들어서 Word2Vec이나 GloVe 등의 임베딩 방법론으로 Bank란 단어를 [0.2 0.8 -1.2]라는 임베딩 벡터로 임베딩하였다고 하면, 이 단어는 Bank Account(은행 계좌)와 River Bank(강둑)에서의 Bank는 전혀 다른 의미임에도 불구하고 두 가지 상황 모두에서 [0.2 0.8 -1.2]의 벡터가 사용된다.\r\n","\r\n","그렇다면 같은 표기의 단어라도 문맥에 따라서 다르게 워드 임베딩을 할 수 있으면 자연어 처리의 성능이 더 올라가지 않을까? 단어를 임베딩하기 전에 전체 문장을 고려해서 임베딩을 하겠다는 것이다. 그래서 탄생한 것이 **문맥을 반영한 워드 임베딩(Contextualized Word Embedding)**이다.\r\n"]},{"cell_type":"markdown","metadata":{"id":"_SVLM_eyM6FY"},"source":["### 2.biLM(Bidirectional Language Model)의 사전 훈련\r\n","\r\n","우선 다음 단어를 예측하는 작업인 언어 모델링을 상기해보자. 아래의 그림은 은닉층이 2개인 일반적인 단방향 RNN 언어 모델의 언어 모델링을 보여준다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/deepbilm.PNG'>\r\n","\r\n","RNN 언어 모델은 문장으로부터 단어 단위로 입력을 받는데, RNN 내부의 은닉 상태 $h_{t}$는 시점(time-step)이 지날수록 점점 업데이트 되어간다. 이는 결과적으로 $h_{t}$의 값이 문장의 문맥 정보를 점차적으로 반영한다고 말할 수 있다. 지금 설명하는 내용은 새로운 개념이 아니라 RNN의 기본 개념이다. 그런데 ELMo는 위의 그림의 순방향 RNN 뿐만 아니라, 위의 그림과는 반대 방향으로 문장을 스캔하는 역방향 RNN 또한 활용한다. ELMo는 양쪽 방향의 언어 모델을 둘 다 활용한다고하여 이 언어 모델을 **biLM(Bidirectional Language Model)**이라고 한다.\r\n","\r\n","ELMo에서 말하는 biLM은 기본적으로 다층 구조(Multi-layer)를 전제로 한다. 은닉층이 최소 2개 이상이라는 의미이다. 아래의 그림은 은닉층이 2개인 순방향 언어 모델과 역방향 언어 모델의 모습을 보여준다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/forwardbackwordlm2.PNG'>\r\n","\r\n","이때 biLM의 입력이 되는 워드 임베딩 방법으로는 이 책에서는 다루지 않는 char CNN이라는 방법을 사용한다. 이 임베딩 방법은 글자(character) 단위로 계산되는데, 이렇게 하면 마치 서브단어(subword)의 정보를 참고하는 것처럼 문맥과 상관없이 dog란 단어와 doggy란 단어의 연관성을 찾아낼 수 있다. 또한 이 방법은 OOV에도 견고하다는 장점이 있다.\r\n","\r\n","주의할 점은 앞서 RNN 챕터에서 설명한 **양방향 RNN**과 ELMo에서의 **biLM**은 다소 다르다. 양방향 RNN은 순방향 RNN의 은닉 상태와 역방향의 RNN의 은닉 상태를 다음 층의 입력으로 보내기 전에 연결(concatenate)시킨다. biLM의 순방향 언어모델과 역방향 언어모델이 각각의 은닉 상태만을 다음 은닉층으로 보내며 훈련시킨 후에 ELMo 표현으로 사용하기 위해서 은닉 상태를 연결(concatenate)시키는 것과는 다르다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"3xPtd7oVM6Hd"},"source":["### 3.biLM의 활용\r\n","\r\n","biLM이 훈련되었다면, 이제 ELMo가 사전 훈련된 biLM을 통해 입력 문장으로부터 단어를 임베딩하기 위한 과정을 보겠다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/playwordvector.PNG'>\r\n","\r\n","이 예제에서는 play란 단어가 임베딩이 되고 있다는 가정 하에 ELMo를 설명한다. play라는 단어를 임베딩하기 위해서 ELMo는 위의 점선의 사각형 내부의 각 층의 결과값을 재료로 사용한다. 다시 말해 해당 시점(time-step)의 biLM의 각 층의 출력값을 가져온다. 그리고 순방향 언어 모델과 역방향 언어 모델의 각 층의 출력값을 연결(concatenate)하고 추가 작업을 진행한다.\r\n","\r\n","여기서 각 층의 출력값이란 첫번째는 임베딩 층을 말하며, 나머지 층은 각 층의 은닉 상태를 말한다. ELMo의 직관적인 아이디어는 각 층의 출력값이 가진 정보는 전부 서로 다른 종류의 정보를 갖고 있을 것이므로, 이들을 모두 활용한다는 점에 있다. 아래는 ELMo가 임베딩 벡터를 얻는 과정을 보여준다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"u58-RgyBM6Jp"},"source":["#### 1) 각 층의 출력값을 연결(concatenate)한다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/concatenate.PNG'>\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"dzzCz0hqM6Lh"},"source":["#### 2) 각 층의 출력값 별로 가중치를 준다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/weight.PNG'>\r\n","\r\n","이 가중치를 여기서는 $s_{1}, s_{2}, s_{3}$라고 하자.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"uWmk1dpYM6N5"},"source":["#### 3) 각 층의 출력값을 모두 더한다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/weightedsum.PNG'>\r\n","\r\n","2)번과 3)번의 단계를 요약하여 가중합(Weighted Sum)을 한다고 할 수 있다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"PT_v9lzBM6Pb"},"source":["#### 4) 벡터의 크기를 결정하는 스칼라 매개변수를 곱한다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/scalarparameter.PNG'>\r\n","\r\n","이 스칼라 매개변수를 여기서는 $γ$라고 하자.\r\n","\r\n","이렇게 완성된 벡터를 ELMo 표현(representation)이라고 한다. 지금까지는 ELMo 표현을 얻기 위한 과정이고 이제 ELMo를 입력으로 사용하고 수행하고 싶은 텍스트 분류, 질의 응답 시스템 등의 자연어 처리 작업이 있을 것이다. 예를 들어 텍스트 분류 작업을 하고 싶다고 가정하자. 그렇다면 ELMo 표현을 어떻게 텍스트 분류 작업에 사용할 수 있을까?\r\n","\r\n","ELMo 표현은 기존의 임베딩 벡터와 함께 사용할 수 있다. 우선 텍스트 분류 작업을 위해서 GloVe와 같은 기존의 방법론을 사용한 임베딩 벡터를 준비했다고 하자. 이 때, GloVe를 사용한 임베딩 벡터만 텍스트 분류 작업에 사용하는 것이 아니라 이렇게 준비된 ELMo 표현을 GloVe 임베딩 벡터와 연결(concatenate)해서 입력으로 사용할 수 있다. 그리고 이 때, ELMo 표현을 만드는데 사용되는 사전 훈련된 언어 모델의 가중치는 고정시킨다. 그리고 대신 위에서 사용한 $s_{1}, s_{2}, s_{3}$와 $γ$는 훈련 과정에서 학습된다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/33930/elmorepresentation.PNG'>\r\n","\r\n","위의 그림은 ELMo 표현이 기존의 GloVe 등과 같은 임베딩 벡터와 함께 NLP 태스크의 입력이 되는 것을 보여준다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"Rgf_yI1CM6Sj"},"source":["### 4.ELMo 표현을 사용해서 스팸 메일 분류하기\r\n","\r\n","이번 예제의 실습은 Colab에서 수행한다고 가정한다. 우선 시작 전에 텐서플로우 버전을 1버전으로 설정하겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KR7AJWOPeU6y","executionInfo":{"status":"ok","timestamp":1615888796072,"user_tz":-540,"elapsed":757,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"d098f9b8-ddb0-42e2-b7f5-0d69b5866e50"},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tusEA9CZeU82"},"source":["텐서플로우 허브로부터 다양한 사전 훈련된 모델(Pre-trained Model)들을 사용할 수 있다. 여기서는 사전 훈련된 모델로부터 ELMo 표현을 사용해보는 정도로 예제를 진행해보겠다. 시작 전에 텐서플로우 허브를 인스톨해야 한다. 윈도우의 명령 프롬프트나 UNIX의 터미널에서 아래의 명령을 수행한다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OAm7qwNeU-x","executionInfo":{"status":"ok","timestamp":1615888890786,"user_tz":-540,"elapsed":5175,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"0daec5b1-1bd0-4a40-a978-fd4618e16e21"},"source":["!pip install tensorflow-hub"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (0.11.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (3.12.4)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (54.0.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XnN6GHsreVA2"},"source":["설치가 끝났다면 이제 텐서플로우 허브를 임포트할 수 있다. 필요한 도구들을 임포트한다.\r\n"]},{"cell_type":"code","metadata":{"id":"O4mQd4WUeVC_","executionInfo":{"status":"ok","timestamp":1615888958040,"user_tz":-540,"elapsed":712,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["import tensorflow_hub as hub\r\n","import tensorflow as tf\r\n","from keras import backend as K\r\n","import urllib.request\r\n","import pandas as pd\r\n","import numpy as np\r\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rkk0XB-weVE6"},"source":["텐서플로우 허브로부터 ELMo를 다운로드하겠다.\r\n"]},{"cell_type":"code","metadata":{"id":"AuRqb0c1eVHA","executionInfo":{"status":"ok","timestamp":1615889031038,"user_tz":-540,"elapsed":7646,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=True)\r\n","# 텐서플로우 허브로부터 ELMo를 다운로드\r\n","\r\n","sess = tf.Session()\r\n","K.set_session(sess)\r\n","sess.run(tf.global_variables_initializer())\r\n","sess.run(tf.tables_initializer())"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kTIRDfRQeVJU"},"source":["기본적으로 필요한 것들을 임포트하였다. 이제 데이터를 불러오고, 5개만 출력해보겠다.\r\n","\r\n","파일 원본 출처 : https://www.kaggle.com/uciml/sms-spam-collection-dataset\r\n","\r\n","스팸 메일 분류하기 데이터를 다운로드하겠다.\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"H7_C-THLeVLa","executionInfo":{"status":"ok","timestamp":1615889087785,"user_tz":-540,"elapsed":1039,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"07082901-a415-4355-81c1-8ec424f3905a"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv\",\r\n","                           filename=\"spam.csv\")\r\n","data = pd.read_csv('spam.csv', encoding='latin-1')\r\n","data[:5]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1  ... Unnamed: 4\n","0   ham  ...        NaN\n","1   ham  ...        NaN\n","2  spam  ...        NaN\n","3   ham  ...        NaN\n","4   ham  ...        NaN\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"iKt4roKTeVPf"},"source":["여기서 필요한 건 v2열과 v1열이다. v1열은 숫자 레이블로 바꿔야 할 필요가 있다. 이를 각각 X_data와 y_data로 저장하겠다.\r\n"]},{"cell_type":"code","metadata":{"id":"AL219WHxeVRn","executionInfo":{"status":"ok","timestamp":1615889178062,"user_tz":-540,"elapsed":887,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["data['v1'] = data['v1'].replace(['ham', 'spam'], [0, 1])\r\n","y_data = list(data['v1'])\r\n","X_data = list(data['v2'])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pBiUmNaxgBov"},"source":["v2열을 X_data에 저장한다. v1열에 있는 ham과 spam 레이블을 각각 숫자 0과 1로 바꾸고 y_data에 저장한다. 정상적으로 저장되었는지 이를 각각 5개만 출력해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50Lh8qZ-gMCn","executionInfo":{"status":"ok","timestamp":1615889225333,"user_tz":-540,"elapsed":782,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"a31f2600-1e65-41f2-8225-cb68b71d08f5"},"source":["X_data[:5]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n"," 'Ok lar... Joking wif u oni...',\n"," \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n"," 'U dun say so early hor... U c already then say...',\n"," \"Nah I don't think he goes to usf, he lives around here though\"]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkNfGqhigNGx","executionInfo":{"status":"ok","timestamp":1615889238951,"user_tz":-540,"elapsed":733,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"ebc48494-5f88-415f-9b28-2d5dea41aafb"},"source":["print(y_data[:5])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[0, 0, 1, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A9TfOKLsgQcE"},"source":["훈련 데이터와 테스트 데이터를 8:2 비율로 분할해보겠다. 그런데 그 전에 이를 위해 전체 데이터 개수의 80%와 20%는 각각 몇 개인지 확인한다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sR4ypedngZ9_","executionInfo":{"status":"ok","timestamp":1615889324629,"user_tz":-540,"elapsed":705,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"2c54875d-9f20-4650-be07-2272ae08a1f5"},"source":["print(len(X_data))\r\n","n_of_train = int(len(X_data) * 0.8)\r\n","n_of_test = int(len(X_data) - n_of_train)\r\n","print(n_of_train)\r\n","print(n_of_test)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["5572\n","4457\n","1115\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mB2Yfb05gldu"},"source":["전체 데이터는 5,572개이며 8:2로 비율하면 4,457과 1,115가 된다. 이를 각각 훈련 데이터와 테스트 데이터의 양으로 하여 데이터를 분할하겠다. \r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"55pcHfCKiZJ1","executionInfo":{"status":"ok","timestamp":1615889817666,"user_tz":-540,"elapsed":692,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["X_train = np.asarray(X_data[:n_of_train]) #X_data 데이터 중에서 앞의 4457개의 데이터만 저장\r\n","y_train = np.asarray(y_data[:n_of_train]) #y_data 데이터 중에서 앞의 4457개의 데이터만 저장\r\n","\r\n","X_test = np.asarray(X_data[n_of_train:]) #X_data 데이터 중에서 뒤의 1115개의 데이터만 저장\r\n","y_test = np.asarray(y_data[n_of_train:]) #y_data 데이터 중에서 뒤의 1115개의 데이터만 저장\r\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RkCsOnjoid1l"},"source":["이제 훈련을 위한 데이터 준비는 끝났다. 이제 ELMo와 설계한 모델을 연결하는 작업들을 진행해보겠다. ELMo는 텐서플로우 허브로부터 가져온 것이기 때문에 케라스에서 사용하기 위해서는 케라스에서 사용할 수 있도록 변환해주는 작업들이 필요하다.\r\n"]},{"cell_type":"code","metadata":{"id":"ff3uNzBEirMH","executionInfo":{"status":"ok","timestamp":1615889995295,"user_tz":-540,"elapsed":755,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def ELMoEmbedding(x):\r\n","    return elmo(tf.squeeze(tf.cast(x, tf.string)), as_dict = True,\r\n","                           signature = 'default')['default']\r\n","# 데이터의 이동이 케라스 → 텐서플로우 → 케라스가 되도록 하는 함수"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"05HGHPwHjJME"},"source":["이제 모델을 설계한다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLqvAtpLjKG9","executionInfo":{"status":"ok","timestamp":1615890152526,"user_tz":-540,"elapsed":1026,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"89fd61ce-a6a2-42c9-af38-8da884dbc507"},"source":["from keras.models import Model\r\n","from keras.layers import Dense, Lambda, Input\r\n","\r\n","input_text = Input(shape = (1, ), dtype = tf.string)\r\n","embedding_layer = Lambda(ELMoEmbedding, output_shape = (1024, ))(input_text)\r\n","hidden_layer = Dense(256, activation = 'relu')(embedding_layer)\r\n","output_layer = Dense(1, activation = 'sigmoid')(hidden_layer)\r\n","\r\n","model = Model(inputs = [input_text], outputs = output_layer)\r\n","model.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 1)                 0         \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               262400    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 262,657\n","Trainable params: 262,657\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOcLLWYwjKJC","executionInfo":{"status":"ok","timestamp":1615890187779,"user_tz":-540,"elapsed":703,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"5c5a0989-9c12-4e50-ff0e-fcdb981175f0"},"source":["model.compile(loss = 'binary_crossentropy',\r\n","              optimizer = 'adam',\r\n","              metrics = ['accuracy'])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"AL5AF6YmjKLB"},"source":["모델은 ELMo를 이용한 임베딩 층을 거쳐서 256개의 뉴런이 있는 은닉층을 거친 후 마지막 1개의 뉴런을 통해 이진 분류를 수행한다. 이진 분류를 위한 마지막 뉴런의 활성화 함수는 시그모이드 함수이며, 모델의 손실 함수는 binary_crossentropy이다.\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kO_ErXhcjKNE","executionInfo":{"status":"ok","timestamp":1615891525678,"user_tz":-540,"elapsed":1241143,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"af924236-b7e1-4084-b0f8-81dca30d9a92"},"source":["history = model.fit(X_train, y_train,\r\n","                    epochs = 1,\r\n","                    batch_size = 60)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","4457/4457 [==============================] - 1239s 278ms/step - loss: 0.0965 - accuracy: 0.9666\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5Quy3Jm7jKPQ"},"source":["훈련 데이터에서는 정확도 96%를 얻었다. 이제 테스트 데이터에 대해서 평가해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Q66faaBkS7V","executionInfo":{"status":"ok","timestamp":1615891822533,"user_tz":-540,"elapsed":296841,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"a21cbf01-5f92-42e6-eef4-e349e9ed4e9c"},"source":["print('\\n 테스트 정확도: %.4f' % (model.evaluate(X_test, y_test)[1]))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["1115/1115 [==============================] - 295s 265ms/step\n","\n"," 테스트 정확도: 0.9812\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9jUsMOv5kS9X"},"source":["1번의 에포크에서 테스트 데이터 정확도 98%를 얻어낸다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"dhwjoNKZjKRS"},"source":["참고 자료 :\r\n","\r\n","http://www.realworldnlpbook.com/blog/improving-sentiment-analyzer-using-elmo.html\r\n","\r\n","https://createmomo.github.io/2018/01/23/Super-Machine-Learning-Revision-Notes/\r\n","\r\n","https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/\r\n","\r\n","http://www.davidsbatista.net/blog/2018/12/06/Word_Embeddings/\r\n","\r\n","https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html#bidirectional-language-model\r\n","\r\n","https://medium.com/saarthi-ai/elmo-for-contextual-word-embedding-for-text-classification-24c9693b0045\r\n","\r\n","char CNN 참고 자료 :\r\n","\r\n","https://www.slideshare.net/JaeminCho6/dl-chatbot-seminar-day-02\r\n","\r\n","한국어에 대한 ELMo :\r\n","\r\n","https://github.com/HIT-SCIR/ELMoForManyLangs\r\n","\r\n","https://ratsgo.github.io/embedding/\r\n","\r\n","ELMo로 단어 몇 개만 임베딩 벡터 얻어보기 :\r\n","\r\n","https://medium.com/@joeyism/embedding-with-tensorflow-hub-in-a-simple-way-using-elmo-d1bfe0ada45c\r\n","\r\n","https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb"]}]}