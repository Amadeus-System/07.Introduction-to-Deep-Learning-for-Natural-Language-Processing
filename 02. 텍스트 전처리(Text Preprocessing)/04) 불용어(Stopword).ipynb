{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02. 텍스트 전처리 / 04) 불용어.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOwbq1dxunscPPOJlJKHenZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"d0SuLOCG-Vui"},"source":["## 04) 불용어(Stopword)\r\n","\r\n","갖고 있는 데이터에서 유의미한 단어 토큰만을 선별하기 위해서는 큰 의미가 없는 단어 토큰을 제거하는 작업이 필요하다. 여기서 큰 의미가 없다라는 것은 자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어들을 말한다. 예를 들면, I, my, me, over, 조사, 접미사 같은 단어들은 문장에서는 자주 등장하지만 실제 의미 분석을 하는데는 거의 기여하는 바가 없는 경우가 있다. 이러한 단어들을 불용어(stopword)라고 하며, NLTK에서는 위와 같은 100여개 이상의 영어 단어들을 불용어로 패키지 내에서 미리 정의하고 있다.\r\n","\r\n","물론 불용어는 개발자가 직접 정의할 수도 있다. 이번 챕터에서는 영어 문장에서 NLTK가 정의한 영어 불용어를 제거하는 실습을 하고, 한국어 문장에서 직접 정의한 불용어를 제거해보겠다.\r\n","\r\n","NLTK 실습에서는 1챕터에서 언급했듯이 NLTK Data가 필요하다. 만약, 데이터가 없다는 에러가 발생 시에는 nltk.download(필요한 데이터)라는 커맨드를 통해 다운로드 할 수 있다. 해당 커맨드 또한 에러가 발생할 경우 1챕터의 NLTK Data 가이드를 참고 바란다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"YjTUGsrx-adz"},"source":["### 1.NLTK에서 불용어 확인하기\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PsH0lU7R-ag4","executionInfo":{"status":"ok","timestamp":1609354384414,"user_tz":-540,"elapsed":691,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"ce0070c0-4dd1-4a99-8da1-21bdc39294f3"},"source":["import nltk\r\n","nltk.download('stopwords')\r\n","from nltk.corpus import stopwords\r\n","\r\n","stopwords.words('english')[:10]"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"vyVCBiSk-ajp"},"source":["stopwords.words(\"english\")는 NLTK가 정의한 영어 불용어 리스트를 리턴한다. 출력 결과가 100개 이상이기 때문에 여기서는 간단히 10개만 확인해보았다. 'i', 'me', 'my'와 같은 단어들을 NLTK에서 불용어로 정의하고 있음을 확인할 수 있다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"qgBNAeNU-amR"},"source":["### 2.NLTK를 통해서 불용어 제거하기\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZi_lxEi-aoq","executionInfo":{"status":"ok","timestamp":1609354569514,"user_tz":-540,"elapsed":1322,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"6910fb32-cf94-47df-9b11-e9a38437451c"},"source":["nltk.download('punkt')\r\n","from nltk.corpus import stopwords\r\n","from nltk.tokenize import word_tokenize\r\n","\r\n","example = \"Family is not an important thing. It's everything.\"\r\n","stop_words = set(stopwords.words('english'))\r\n","\r\n","word_tokens = word_tokenize(example)\r\n","\r\n","result = []\r\n","for w in word_tokens:\r\n","    if w not in stop_words:\r\n","        result.append(w)\r\n","\r\n","print(word_tokens)\r\n","print(result)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n","['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QBrxEw3I-arr"},"source":["위 코드는 \"Family is not an important thing. It's everything.\"이라는 임의의 문장을 정의하고, NLTK가 정의하고 있는 불용어를 제외한 결과를 출력하고 있다. 'is', 'not', 'an'과 같은 단어들이 문장에서 제거되었음을 볼 수 있다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"qtmgwMEy-auY"},"source":["### 3.한국어에서 불용어 제거하기\r\n","\r\n","한국어에서 불용어를 제거하는 방법으로는 간단하게는 토큰화 후에 조사, 접속사 등을 제거하는 방법이 있다. 하지만 불용어를 제거하려고 하다보면 조사나 접속사와 같은 단어들뿐만 아니라 명사, 형용사와 같은 단어들 중에서 불용어로서 제거하고 싶은 단어들이 생기기도 한다. 결국에는 사용자가 직접 불용어 사전을 만들게 되는 경우가 많다. 이번에는 직접 불용어를 정의해보고, 주어진 문장으로부터 직접 정의한 불용어 사전을 참고로 불용어를 제거해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CCGVYITu-a7-","executionInfo":{"status":"ok","timestamp":1609354901321,"user_tz":-540,"elapsed":907,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"355c32a5-73d0-40af-e118-09ec3cc64237"},"source":["from nltk.corpus import stopwords\r\n","from nltk.tokenize import word_tokenize\r\n","\r\n","example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\r\n","stop_words = \"아무거나 아무렇게나 어찌하든지 같다 비슷하다 예컨대 이럴정도로 하면 아니거든\"\r\n","\r\n","# 위의 불용어는 명사가 아닌 단어 중에서 저자가 임의로 선정한 것으로\r\n","# 실제 의미있는 선정 기준이 아니다.\r\n","stop_words = stop_words.split(' ')\r\n","word_tokens = word_tokenize(example)\r\n","\r\n","result = []\r\n","for w in word_tokens:\r\n","    if w not in stop_words:\r\n","        result.append(w)\r\n","# 위의 4줄은 아래의 한 줄로 대체 가능\r\n","# result = [word for word in word_tokens if not word in stop_words]\r\n","\r\n","print(word_tokens)\r\n","print(result)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['고기를', '아무렇게나', '구우려고', '하면', '안', '돼', '.', '고기라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n","['고기를', '구우려고', '안', '돼', '.', '고기라고', '다', '같은', '게', '.', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_S7YNfCJ-a-f"},"source":["아래의 링크는 보편적으로 선택할 수 있는 한국어 불용어 리스트를 보여준다. (여전히 절대적인 기준은 아니다.)\r\n","\r\n","링크 : https://www.ranks.nl/stopwords/korean\r\n","\r\n","한국어 불용어를 제거하는 더 좋은 방법은 코드 내에서 직접 정의하지 않고 txt 파일이나 csv 파일로 수많은 불용어를 정리해놓고, 이를 불러와서 사용하는 방법이다.\r\n","\r\n","추가 참고 가능한 한국어 불용어 리스트 :\r\n","\r\n","https://bab2min.tistory.com/544"]}]}