{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12. NLP를 위한 합성곱 신경망 / 2) 자연어 처리를 위한 1D CNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPgC5odUiVhN2NneugRidGS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HfelJ1Q0HH8L"},"source":["## 2) 자연어 처리를 위한 1D CNN(1D Convolutional Neural Networks)\r\n","\r\n","이번 챕터에서는 앞서 배운 합성곱 신경망을 자연어 처리에서 사용하기 위한 1D CNN을 이해해보겠다.\r\n"]},{"cell_type":"markdown","metadata":{"id":"W-edvIweHM3v"},"source":["### 1.2D 합성곱(2D Convolutions)\r\n","\r\n","합성곱 신경망은 자연어 처리보다는 이미지나 영상 처리와 같은 비전 분야에 사용되는 것으로 좀 더 잘 알려져있다. 이때 주로 사용되는 2D 합성곱을 복습해보겠다.\r\n","\r\n","2D 합성곱은 합성곱 연산을 통해서 **이미지의 특징을 추출**하는 역할을 한다. 합성곱은 영어로 컨볼루션이라고도 불리는데, **커널(kernel)** 또는 **필터(filter)**라는 $n × m$ 크기의 행렬로 $높이(height) × 너비(width)$ 크기의 이미지를 처음부터 끝까지 겹치며 훑으면서 $n × m$ 크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 것을 말한다. 이때, 이미지의 가장 왼쪽 위부터 가장 오른쪽까지 순차적으로 훑는다.\r\n","\r\n","* 커널(kernel)은 일반적으로 3 x 3 또는 5 x 5를 사용한다.\r\n","\r\n","예를 통해 이해해보자. 아래는 $3 × 3$ 크기의 커널로 $5 × 5$의 이미지 행렬에 합성곱 연산을 수행하는 과정을 보여준다. 한 번의 연산을 1 스텝(step)이라고 하였을 때, 합성곱 연산의 네번째 스텝까지 이미지와 식으로 표현해보았다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"pMjXl6JgHM6R"},"source":["#### 1.첫번째 스텝\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/64066/conv4.png' width = 60%>\r\n","\r\n","(1×1) + (2×0) + (3×1) + (2×1) + (1×0) + (0×1) + (3×0) + (0×1) + (1×0) = 6\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"tw7dKpDuHM8k"},"source":["#### 2.두번째 스텝\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/64066/conv5.png' width = 60%>\r\n","\r\n","(2×1) + (3×0) + (4×1) + (1×1) + (0×0) + (1×1) + (0×0) + (1×1) + (1×0) = 9\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"sjuIT4h_HM-p"},"source":["#### 3.세번째 스텝\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/64066/conv6.png' width = 60%>\r\n","\r\n","(3×1) + (4×0) + (5×1) + (0×1) + (1×0) + (2×1) + (1×0) + (1×1) + (0×0) = 11\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"XP59oH9nHNCE"},"source":["#### 4.네번째 스텝\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/64066/conv7.png' width = 60%>\r\n","\r\n","(2×1) + (1×0) + (0×1) + (3×1) + (0×0) + (1×1) + (1×0) + (4×1) + (1×0) = 10\r\n","\r\n","위 연산을 총 9번의 스텝까지 마쳤다고 가정하였을 때, 최종 결과는 아래와 같다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/64066/conv8.png' width = 60%>\r\n","\r\n","위와 같이 입력으로부터 커널을 사용하여 합성곱 연산을 통해 나온 결과를 **특성 맵(feature map)**이라고 한다.\r\n","\r\n","위의 예제에서는 커널의 크기가 3 x 3이었지만, 커널의 크기는 사용자가 정할 수 있다. 또한 커널의 이동 범위가 위의 예제에서는 한 칸이었지만, 이 또한 사용자가 정할 수 있다. 이러한 이동 범위를 **스트라이드(stride)**라고 한다.\r\n","\r\n","아래의 예제는 스트라이드가 2일 경우에 5 x 5 이미지에 합성곱 연산을 수행하는 3 x 3 커널의 움직임을 보여준다. 최종적으로 2 x 2의 크기의 특성 맵을 얻는다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/64066/conv9.png' width = 60%>\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"loE58DKTHNEc"},"source":["### 2.1D 합성곱(1D Convolutions)\r\n","\r\n","지금까지는 이미지 처리에서 사용되는 CNN을 위주로 설명했다. 이 책은 자연어 처리를 다루지만, 이미지 처리에서 CNN이 어떻게 사용되느냐를 먼저 이해해야 된다고 판단해서 이를 설명했다. 이제 본격적으로 자연어 처리에 사용되는 1D CNN을 학습한다.\r\n","\r\n","LSTM을 이용한 여러 실습을 상기해보면, 각 문장은 임베딩 층(embedding layer)을 지나서 각 단어가 임베딩 벡터가 된 상태로 LSTM의 입력이 되었다. 이는 1D CNN도 마찬가지이다. 1D CNN도 입력이 되는 것은 각 단어가 벡터로 변환된 문장 행렬로 LSTM과 입력을 받는 형태는 동일하다.\r\n","\r\n","'wait for the video and don't rent it'이라는 문장이 있을 때, 이 문장이 토큰화, 패딩, 임베딩 층(Embedding layer)을 거친다면 다음과 같은 문장 형태의 행렬로 변환될 것이다. 아래 그림에서 $n$은 문장의 길이, $k$는 임베딩 벡터의 차원이다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/80437/sentence_matrix.PNG' width = 60%>\r\n","\r\n","그리고 이 행렬이 만약 LSTM의 입력으로 주어진다면, LSTM은 첫번째 시점에는 첫번째 행을 입력으로 받고, 두번째 시점에는 두번째 행을 입력으로 받으며 순차적으로 단어를 처리한다. 그렇다면 1D CNN의 경우에는 저 행렬을 어떻게 처리할까?\r\n","\r\n","1D CNN에서 커널의 너비는 문장 행렬에서의 임베딩 벡터의 차원과 동일하게 설정된다. 그렇기 때문에 1D CNN에서는 높이 사이즈만을 명명하여 해당 커널의 사이즈라고 간주한다. 가령, 커널의 사이즈가 2인 경우에는 아래의 그림과 같이 높이가 2, 너비가 임베딩 벡터의 차원인 커널이 사용된다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/80437/1d_cnn.PNG' width = 60%>\r\n","\r\n","커널의 너비가 임베딩 벡터의 차원이라는 의미는 커널이 2D CNN때와는 달리 너비 방향으로는 더 이상 움직일 곳이 없다는 것을 의미한다. 그래서 1D CNN에서는 커널이 문장 행렬의 높이 방향으로만 움직이게 되어있다. 쉽게 설명하면, 위 그림에서 커널은 2D CNN때와는 달리 오른쪽으로는 움직일 공간이 없으므로, 아래쪽으로만 이동해야 한다.\r\n","\r\n","한 번의 연산을 1 스텝(step)이라고 하였을 때, 합성곱 연산의 네번째 스텝까지 표현한 이미지는 다음과 같다. 사이즈가 2인 커널은 처음에는 'wait for'에 대해서 합성곱 연산을 하고, 두번째 스텝에는 'for the'에 대해서 연산을, 세번째 스텝에는 'the video'에 대해서 연산을, 네번째 스텝에서는 'video and'에 대해서 연산을 하게 된다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/80437/%EB%84%A4%EB%B2%88%EC%A7%B8%EC%8A%A4%ED%85%9D.PNG' width = 60%>\r\n","\r\n","이렇게 여덟번째 스텝까지 반복하였을 때, 결과적으로는 우측의 8차원 벡터를 1D CNN의 결과로서 얻게 될 것이다. 그런데 커널의 사이즈가 꼭 2일 필요가 있을까? 2D CNN에서 커널의 사이즈가 3 x 3 또는 5 x 5 또는 동등의 여러 사이즈의 커널을 자유자재로 사용할 수 있었듯이, 1D CNN에서도 커널의 사이즈는 여러분이 마음대로 변경할 수 있다. 가령, 커널의 사이즈를 3으로 한다면, 네번째 스텝에서의 연산은 아래의 그림과 같을 것이다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/80437/%EC%BB%A4%EB%84%903.PNG' width = 60%>\r\n","\r\n","커널의 사이즈가 달라진다는 것은 어떤 의미가 있을까? CNN에서의 커널은 신경망 관점에서는 가중치 행렬이므로 커널의 사이즈에 따라 학습하게 되는 파라미터의 수는 달라진다. 1D CNN과 자연어 처리 관점에서는 커널의 사이즈에 따라서 참고하는 단어의 묶음의 크기가 달라진다. 이는 참고하는 n-gram이 달라진다고 볼 수 있다. 가령, 커널의 사이즈가 2라면 각 연산의 스텝에서 참고하는 것은 bigram이다. 커널의 사이즈가 3이라면 각 연산의 스텝에서 참고하는 것은 trigram이다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"TL-nZ2v9HNHv"},"source":["### 3.맥스 풀링(Max-pooling)\r\n","\r\n","2D CNN을 이용한 이미지 처리에서도 그랬지만, 일반적으로 1D CNN에서도 합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층을 추가하게 된다. 그 중 대표적으로 사용되는 것이 맥스 풀링(Max-pooling)이다. 맥스 풀링은 각 합성곱 연산으로부터 얻은 결과 벡터에서 가장 큰 값을 가진 스칼라 값을 빼내는 연산이다.\r\n","\r\n","가령, 아래의 그림은 사이즈가 2인 커널과 사이즈가 3인 커널 두 개의 커널로부터 각각 결과 벡터를 얻고, 각 벡터에서 가장 큰 값을 꺼내오는 맥스 풀링 연산을 보여준다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/80437/%EB%A7%A5%EC%8A%A4%ED%92%80%EB%A7%81.PNG' width = 60%>\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"URyMnoCZHNKG"},"source":["### 4.신경망 설계하기\r\n","\r\n","지금까지 배운 개념들을 가지고 텍스트 분류를 위한 CNN을 설계해보자. 우선, 설계하고자 하는 신경망은 이진 분류를 위한 신경망이다. 단, 시그모이드 함수가 아니라 소프트맥스 함수를 사용할 것이므로 출력층에서 뉴런의 개수가 2인 신경망을 설계한다.\r\n","\r\n","<img src = 'https://wikidocs.net/images/page/80437/conv1d.PNG' width = 60%>\r\n","\r\n","커널은 사이즈가 4인 커널 2개, 3인 커널 2개, 2인 커널 2개를 사용한다. 문장의 길이가 9인 경우, 합성곱 연산을 한 후에는 각각 6차원 벡터 2개, 7차원 벡터 2개, 8차원 벡터 2개를 얻는다. 벡터가 6개이므로 맥스 풀링을 한 후에는 6개의 스칼라 값을 얻는데, 일반적으로 이렇게 얻은 스칼라값들은 전부 연결(concatenate)하여 하나의 벡터로 만들어준다. 이렇게 얻은 벡터는 1D CNN을 통해서 문장으로부터 얻은 최종 특성 벡터로 이를 뉴런이 2개인 출력층에 완전 연결시킴으로써(Dense layer를 사용) 텍스트 분류를 수행한다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"D4ddSeETOAFA"},"source":["http://www.joshuakim.io/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-embeddings/\r\n","\r\n","https://www.datasciencecentral.com/profiles/blogs/sentence-classification-using-cnns\r\n","\r\n","https://towardsdatascience.com/character-level-cnn-with-keras-50391c3adf33"]}]}