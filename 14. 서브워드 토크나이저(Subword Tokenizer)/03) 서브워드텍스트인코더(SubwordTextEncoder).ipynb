{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03) 서브워드텍스트인코더(SubwordTextEncoder).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNHckdt+69Oz/e4Ye+g0+kR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MAMF0PkEgXXi"},"source":["## 03) 서브워드텍스트인코더(SubwordTextEncoder)\n","\n","SubwordTextEncoder는 텐서플로우를 통해 사용할 수 있는 서브워드 토크나이저이다. BPE와 유사한 알고리즘인 Wordpiece Model을 채택하였으며, 패키지를 통해 쉽게 단어들을 서브워드들로 분리할 수 있다. \n","\n","SubwordTextEncoder를 통해서 IMDB 영화 리뷰 데이터와 네이버 영화 리뷰 데이터에 대해서 토큰화 작업을 수행해보자.\n","\n","```\n","Tensorflow 2.3+ 버전에서는 tfds.features.text 대신 tfds.deprecated.text라고 작성해야 한다.\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AxNJ84EygisU"},"source":["### 1.IMDB 리뷰 토큰화하기\n","\n"]},{"cell_type":"code","metadata":{"id":"aifSWwGEgiuZ","executionInfo":{"status":"ok","timestamp":1617097714496,"user_tz":-540,"elapsed":2942,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["import tensorflow_datasets as tfds\n","import urllib.request\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3SzLgV5Zgiw0","executionInfo":{"status":"ok","timestamp":1617097720778,"user_tz":-540,"elapsed":1128,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"c240d8cd-b327-4466-a3b5-71421ff09fca"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\",\n","                           filename=\"IMDb_Reviews.csv\")\n"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x7f1cb1e1fad0>)"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSNRRVUJgiyx","executionInfo":{"status":"ok","timestamp":1617097721834,"user_tz":-540,"elapsed":679,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"4657e278-503d-48f4-9823-c59e60fdb70d"},"source":["ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["IMDb_Reviews.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LWsaXtsTgi04"},"source":["다운로드한 데이터를 데이터프레임에 저장한다.\n"]},{"cell_type":"code","metadata":{"id":"on9Ji70Ogi4-","executionInfo":{"status":"ok","timestamp":1617097752718,"user_tz":-540,"elapsed":1127,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["train_df = pd.read_csv('IMDb_Reviews.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tH06xZ8igi7N"},"source":["데이터프레임에서 'review'에 해당하는 열이 토큰화를 수행해야 할 데이터이다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvgJCkq4gi9N","executionInfo":{"status":"ok","timestamp":1617097777523,"user_tz":-540,"elapsed":439,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"29bd3afa-ff75-435a-d4dd-0437ae428284"},"source":["train_df['review']"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        My family and I normally do not watch local mo...\n","1        Believe it or not, this was at one time the wo...\n","2        After some internet surfing, I found the \"Home...\n","3        One of the most unheralded great works of anim...\n","4        It was the Sixties, and anyone with long hair ...\n","                               ...                        \n","49995    the people who came up with this are SICK AND ...\n","49996    The script is so so laughable... this in turn,...\n","49997    \"So there's this bride, you see, and she gets ...\n","49998    Your mind will not be satisfied by this nobud...\n","49999    The chaser's war on everything is a weekly sho...\n","Name: review, Length: 50000, dtype: object"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"CwUHO5VPgi_P"},"source":["tfds.features.text.SubwordTextEncoder.build_from_corpus의 인자로 토큰화할 데이터를 넣어준다. 이 작업을 통해서 서브워드들로 이루어진 단어 집합(Vocabulary)를 생성하고, 각 서브워드에 고유한 정수를 부여한다.\n","\n"]},{"cell_type":"code","metadata":{"id":"4o4ulnkYgjBi","executionInfo":{"status":"ok","timestamp":1617098390168,"user_tz":-540,"elapsed":320938,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    train_df['review'], target_vocab_size = 2**13)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M8caNn7IgjDw"},"source":[".subwords를 통해서 토큰화된 서브워드들을 확인할 수 있다. 100개만 출력해보자.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MWS6aYXgjF4","executionInfo":{"status":"ok","timestamp":1617098391225,"user_tz":-540,"elapsed":1042,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"099d508e-6e94-498f-bdeb-f3e1287d084b"},"source":["print(tokenizer.subwords[:100])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br', 'in_', 'I_', 'that_', 'this_', 'it_', ' /><', ' />', 'was_', 'The_', 't_', 'as_', 'with_', 'for_', '.<', 'on_', 'but_', 'movie_', 'are_', ' (', 'have_', 'his_', 'film_', 'not_', 'be_', 'you_', 'ing_', ' \"', 'ed_', 'it', 'd_', 'an_', 'at_', 'by_', 'he_', 'one_', 'who_', 'from_', 'y_', 'or_', 'e_', 'like_', 'all_', '\" ', 'they_', 'so_', 'just_', 'has_', ') ', 'about_', 'her_', 'out_', 'This_', 'some_', 'movie', 'ly_', 'film', 'very_', 'more_', 'It_', 'what_', 'would_', 'when_', 'if_', 'good_', 'up_', 'which_', 'their_', 'only_', 'even_', 'my_', 'really_', 'had_', 'can_', 'no_', 'were_', 'see_', '? ', 'she_', 'than_', '! ', 'there_', 'been_', 'get_', 'into_', 'will_', ' - ', 'much_', 'n_', 'because_', 'ing']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o_28Q1DcgjIO"},"source":["임의로 선택한 21번째 샘플을 출력해보고, 정수 인코딩을 수행한 결과와 비교해보겠다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jd5aMJgNgjKI","executionInfo":{"status":"ok","timestamp":1617098391225,"user_tz":-540,"elapsed":1038,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"e901278c-56e7-4e0f-d1be-d36e21584908"},"source":["print(train_df['review'][20])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Pretty bad PRC cheapie which I rarely bother to watch over again, and it's no wonder -- it's slow and creaky and dull as a butter knife. Mad doctor George Zucco is at it again, turning a dimwitted farmhand in overalls (Glenn Strange) into a wolf-man. Unfortunately, the makeup is virtually non-existent, consisting only of a beard and dimestore fangs for the most part. If it were not for Zucco and Strange's presence, along with the cute Anne Nagel, this would be completely unwatchable. Strange, who would go on to play Frankenstein's monster for Unuiversal in two years, does a Lenny impression from \"Of Mice and Men\", it seems.<br /><br />*1/2 (of Four)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N_Q6otQpgjMI"},"source":["encode()를 통해서 입력한 데이터에 대해서 정수 인코딩을 수행한 결과를 얻을 수 있다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezEM8yDHj83G","executionInfo":{"status":"ok","timestamp":1617098391226,"user_tz":-540,"elapsed":1036,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"0024b407-e9e3-473f-d924-e8607664ff45"},"source":["print('Tokenized sample question : {}'.format(tokenizer.encode(train_df['review'][20])))\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Tokenized sample question : [1590, 4162, 132, 7107, 1892, 2983, 578, 76, 12, 4632, 3422, 7, 160, 175, 372, 2, 5, 39, 8051, 8, 84, 2652, 497, 39, 8051, 8, 1374, 5, 3461, 2012, 48, 5, 2263, 21, 4, 2992, 127, 4729, 711, 3, 1391, 8044, 3557, 1277, 8102, 2154, 5681, 9, 42, 15, 372, 2, 3773, 4, 3502, 2308, 467, 4890, 1503, 11, 3347, 1419, 8127, 29, 5539, 98, 6099, 58, 94, 4, 1388, 4230, 8057, 213, 3, 1966, 2, 1, 6700, 8044, 9, 7069, 716, 8057, 6600, 2, 4102, 36, 78, 6, 4, 1865, 40, 5, 3502, 1043, 1645, 8044, 1000, 1813, 23, 1, 105, 1128, 3, 156, 15, 85, 33, 23, 8102, 2154, 5681, 5, 6099, 8051, 8, 7271, 1055, 2, 534, 22, 1, 3046, 5214, 810, 634, 8120, 2, 14, 71, 34, 436, 3311, 5447, 783, 3, 6099, 2, 46, 71, 193, 25, 7, 428, 2274, 2260, 6487, 8051, 8, 2149, 23, 1138, 4117, 6023, 163, 11, 148, 735, 2, 164, 4, 5277, 921, 3395, 1262, 37, 639, 1349, 349, 5, 2460, 328, 15, 5349, 8127, 24, 10, 16, 10, 17, 8054, 8061, 8059, 8062, 29, 6, 6607, 8126, 8053]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NbJEWJHlkEJU"},"source":["임의로 선택한 짧은 문장에 대해서 정수 인코딩 결과를 확인하고, 이를 다시 역으로 디코딩해보겠다. 디코딩할 때는 인코딩할 때 encode()를 사용한 것과 유사하게 decode()를 통해서 할 수 있다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ntA64SfxkPIK","executionInfo":{"status":"ok","timestamp":1617098391226,"user_tz":-540,"elapsed":1031,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"aa60e2fe-ae47-432e-a1b2-dd0d67d69d48"},"source":["# train_df에 존재하는 문장 중 일부를 발췌\n","sample_string = \"It's mind-blowing to me that this film was even made.\"\n","\n","# 인코딩한 결과를 tokenized_string에 저장\n","tokenized_string = tokenizer.encode(sample_string)\n","print('정수 인코딩 후의 문장: {}'.format(tokenized_string))\n","\n","# 이를 다시 디코딩\n","original_string = tokenizer.decode(tokenized_string)\n","print('기존 문장: {}'.format(original_string))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["정수 인코딩 후의 문장: [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 79, 681, 8058]\n","기존 문장: It's mind-blowing to me that this film was even made.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C7nMp6qGksD9"},"source":[".vocab_size를 통해 단어 집합의 크기를 확인할 수 있다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROxQ7Dgakv39","executionInfo":{"status":"ok","timestamp":1617098523469,"user_tz":-540,"elapsed":682,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"eb583fa1-6b05-4f9f-9814-4e4e8049ab9f"},"source":["print('단어 집합의 크기(Vocab size) :', tokenizer.vocab_size)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["단어 집합의 크기(Vocab size) : 8268\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FMbC6pi0lUCD"},"source":["현재 단어 집합의 크기는 8,268개이다. 디코딩 결과를 병렬적으로 나열하여 각 단어와 맵핑된 정수를 확인해보자.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmxv0B8MpO6q","executionInfo":{"status":"ok","timestamp":1617099581350,"user_tz":-540,"elapsed":717,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"e1b75936-90c0-4942-c479-d1dec6265a45"},"source":["for ts in tokenized_string:\n","    print('{} ----> {}'.format(ts, tokenizer.decode([ts])))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["137 ----> It\n","8051 ----> '\n","8 ----> s \n","910 ----> mind\n","8057 ----> -\n","2169 ----> blow\n","36 ----> ing \n","7 ----> to \n","103 ----> me \n","13 ----> that \n","14 ----> this \n","32 ----> film \n","18 ----> was \n","79 ----> even \n","681 ----> made\n","8058 ----> .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9H85U72ppWLm"},"source":["이번에는 기존 예제 문장 중 even이라는 단어에 임의로 xyz라는 3개의 글자를 추가해보았다. 현재 토크나이저가 even이라는 단어를 이미 하나의 서브워드로 인식하고 있는 상황에서 나머지 xyz를 어떻게 분리하는지를 확인하기 위함이다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjtlWMUnplJS","executionInfo":{"status":"ok","timestamp":1617099729728,"user_tz":-540,"elapsed":703,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"b941ca83-0532-4b78-9b10-0b1e897bae52"},"source":["# 앞서 실습한 문장에 even 뒤에 임의로 xyz 추가\n","sample_string = \"It's mind-blowing to me that this film was evenxyz made.\"\n","\n","# 인코딩한 결과를 tokenized_string에 저장\n","tokenized_string = tokenizer.encode(sample_string)\n","print('정수 인코딩 후의 문장: {}'.format(tokenized_string))\n","\n","# 이를 다시 디코딩\n","original_string = tokenizer.decode(tokenized_string)\n","print('기존 문장: {}'.format(original_string))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["정수 인코딩 후의 문장: [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 7974, 8132, 8133, 997, 681, 8058]\n","기존 문장: It's mind-blowing to me that this film was evenxyz made.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxssYU7wplLk","executionInfo":{"status":"ok","timestamp":1617099782602,"user_tz":-540,"elapsed":710,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"69625d9e-7e5c-4a32-9558-9cce7d0a136d"},"source":["for ts in tokenized_string:\n","    print('{} ----> {}'.format(ts, tokenizer.decode([ts])))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["137 ----> It\n","8051 ----> '\n","8 ----> s \n","910 ----> mind\n","8057 ----> -\n","2169 ----> blow\n","36 ----> ing \n","7 ----> to \n","103 ----> me \n","13 ----> that \n","14 ----> this \n","32 ----> film \n","18 ----> was \n","7974 ----> even\n","8132 ----> x\n","8133 ----> y\n","997 ----> z \n","681 ----> made\n","8058 ----> .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fOYxVJeSplOF"},"source":["evenxyz에서 even을 독립적으로 분리하고 xyz는 훈련 데이터에서 하나의 단어로서 등장한 적이 없으므로 각각 전부 분리된다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C2-Zqe7TplQo"},"source":["### 2.네이버 영화 리뷰 토큰화하기\n","\n","네이버 영화 리뷰에 대해서도 위에서 IMDB 영화 리뷰에 대해서 수행한 동일한 작업을 진행해보자.\n","\n"]},{"cell_type":"code","metadata":{"id":"NYfe-XSYplTC","executionInfo":{"status":"ok","timestamp":1617099868942,"user_tz":-540,"elapsed":743,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["import tensorflow_datasets as tfds\n","import urllib.request"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2ZX7eqUplVP","executionInfo":{"status":"ok","timestamp":1617099876813,"user_tz":-540,"elapsed":1709,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"b5873fe0-1255-4b8e-9227-d30a9defb47f"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\",\n","                           filename=\"ratings_train.txt\")\n"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ratings_train.txt', <http.client.HTTPMessage at 0x7f1ca8f9fd10>)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66OdVodsplXd","executionInfo":{"status":"ok","timestamp":1617099877767,"user_tz":-540,"elapsed":952,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"d7b4bd95-c963-4f16-c006-fbcec41957d8"},"source":["ls"],"execution_count":22,"outputs":[{"output_type":"stream","text":["IMDb_Reviews.csv  ratings_train.txt  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sYNQxioEplZx"},"source":["다운로드한 데이터를 데이터프레임에 저장한다.\n"]},{"cell_type":"code","metadata":{"id":"m2ps-j_gplbq","executionInfo":{"status":"ok","timestamp":1617099899587,"user_tz":-540,"elapsed":1144,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["train_data = pd.read_table('ratings_train.txt')"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oP6CZG_-pld6"},"source":["이 데이터에는 Null 값이 존재하므로 이를 제거해준다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IueDs6BSpliE","executionInfo":{"status":"ok","timestamp":1617099919241,"user_tz":-540,"elapsed":722,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"9d0e98b2-8a05-4545-84ec-dd11d3d26645"},"source":["print(train_data.isnull().sum())"],"execution_count":24,"outputs":[{"output_type":"stream","text":["id          0\n","document    5\n","label       0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3waHAUEUplkj","executionInfo":{"status":"ok","timestamp":1617099956980,"user_tz":-540,"elapsed":686,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"ae3e80ff-7d81-4184-d069-3acd0e403a0f"},"source":["train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"],"execution_count":25,"outputs":[{"output_type":"stream","text":["False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4-y5W_4jqpg1"},"source":["tfds.features.text.SubwordTextEncoder.build_from_corpus의 인자로 네이버 영화 리뷰 데이터를 넣어서, 서브워드들로 이루어진 단어 집합(Vocabulary)를 생성하고, 각 서브워드에 고유한 정수를 부여한다. "]},{"cell_type":"code","metadata":{"id":"OS9KJoA3qpi6","executionInfo":{"status":"ok","timestamp":1617100496275,"user_tz":-540,"elapsed":453098,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    train_data['document'], target_vocab_size = 2**13)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hlWyv3FQqplB"},"source":["토큰화된 100개의 서브워드들을 출력해보자.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGiptSrLqpns","executionInfo":{"status":"ok","timestamp":1617100497399,"user_tz":-540,"elapsed":1112,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"f37906fb-c109-43c2-8478-ba3bef0d0fff"},"source":["print(tokenizer.subwords[:100])"],"execution_count":27,"outputs":[{"output_type":"stream","text":["['. ', '..', '영화', '이_', '...', '의_', '는_', '도_', '다', ', ', '을_', '고_', '은_', '가_', '에_', '.. ', '한_', '너무_', '정말_', '를_', '고', '게_', '영화_', '지', '... ', '진짜_', '이', '다_', '요', '만_', '? ', '과_', '나', '가', '서_', '지_', '로_', '으로_', '아', '어', '....', '음', '한', '수_', '와_', '도', '네', '그냥_', '나_', '더_', '왜_', '이런_', '면_', '기', '하고_', '보고_', '하는_', '서', '좀_', '리', '자', '스', '안', '! ', '에서_', '영화를_', '미', 'ㅋㅋ', '네요', '시', '주', '라', '는', '오', '없는_', '에', '해', '사', '!!', '영화는_', '마', '잘_', '수', '영화가_', '만', '본_', '로', '그_', '지만_', '대', '은', '비', '의', '일', '개', '있는_', '없다', '함', '구', '하']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1s1jyIO8qppY"},"source":["encode()를 통해 임의로 선택한 21번째 샘플을 인코딩한다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"geXqqbMHqprv","executionInfo":{"status":"ok","timestamp":1617100497400,"user_tz":-540,"elapsed":1108,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"d15d504d-cf72-4bc2-afa7-e44dced26377"},"source":["print('Tokenized sample question: {}'.format(tokenizer.encode(train_data['document'][20])))\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Tokenized sample question: [669, 4700, 17, 1749, 8, 96, 131, 1, 48, 2239, 4, 7466, 32, 1274, 2655, 7, 80, 749, 1254]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tsgxSe_Pqptw"},"source":["21번째 샘플에 대해서 정수 인코딩 결과를 확인하고, 이를 다시 역으로 디코딩해보겠다. 디코딩할 때는 인코딩할 때 encode()를 사용한 것과 유사하게 decode()를 통해서 할 수 있다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"go6D1wbpqpv7","executionInfo":{"status":"ok","timestamp":1617101204125,"user_tz":-540,"elapsed":520,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"74dba129-f819-45eb-fcf7-37571d46d0de"},"source":["sample_string = train_data['document'][21]\n","\n","# 인코딩한 결과를 tokenized_string에 저장\n","tokenized_string = tokenizer.encode(sample_string)\n","print('정수 인코딩 후의 문장: {}'.format(tokenized_string))\n","\n","# 이를 다시 디코딩\n","original_string = tokenizer.decode(tokenized_string)\n","print('기존 문장: {}'.format(original_string))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["정수 인코딩 후의 문장: [570, 892, 36, 584, 159, 7091, 201]\n","기존 문장: 보면서 웃지 않는 건 불가능하다\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CFWaUYK1qpx7"},"source":["이번에는 임의로 작성한 짧은 문장에 대해서 정수 인코딩 결과를 확인하고, 이를 다시 역으로 디코딩해보겠다. 기존 훈련 데이터에 없을만한 '킄핫핫'을 추가해보았다. 서브워드텍스트인코더는 이 경우 음절 이하 단위로 분리하고, 또한 정상적으로 디코딩한다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jQRCGfoqp0S","executionInfo":{"status":"ok","timestamp":1617101275246,"user_tz":-540,"elapsed":700,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"ca6e6a3d-e38d-46b9-8597-8290909d5abd"},"source":["sample_string = '이 영화 굉장히 재밌다 킄핫핫ㅎ'\n","\n","# 인코딩한 결과를 tokenized_string에 저장\n","tokenized_string = tokenizer.encode(sample_string)\n","print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n","\n","# 이를 다시 디코딩\n","original_string = tokenizer.decode(tokenized_string)\n","print ('기존 문장: {}'.format(original_string))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["정수 인코딩 후의 문장 [4, 23, 1364, 2157, 8235, 8128, 8130, 8235, 8147, 8169, 8235, 8147, 8169, 393]\n","기존 문장: 이 영화 굉장히 재밌다 킄핫핫ㅎ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rk72u8j1qp2H","executionInfo":{"status":"ok","timestamp":1617101302645,"user_tz":-540,"elapsed":732,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"5fb6874c-904f-4515-d33b-d5bff917ed0f"},"source":["for ts in tokenized_string:\n","    print('{} ----> {}'.format(ts, tokenizer.decode([ts])))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["4 ----> 이 \n","23 ----> 영화 \n","1364 ----> 굉장히 \n","2157 ----> 재밌다 \n","8235 ----> �\n","8128 ----> �\n","8130 ----> �\n","8235 ----> �\n","8147 ----> �\n","8169 ----> �\n","8235 ----> �\n","8147 ----> �\n","8169 ----> �\n","393 ----> ㅎ\n"],"name":"stdout"}]}]}