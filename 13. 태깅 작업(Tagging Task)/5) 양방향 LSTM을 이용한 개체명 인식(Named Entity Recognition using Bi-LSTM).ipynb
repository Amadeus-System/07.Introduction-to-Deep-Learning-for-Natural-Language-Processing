{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5) 양방향 LSTM을 이용한 개체명 인식(Named Entity Recognition using Bi-LSTM).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOVGAil2Fjeb/EBBm1f5Y6B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WJSk1WMfptbS"},"source":["## 5) 양방향 LSTM을 이용한 개체명 인식(Named Entity Recognition using Bi-LSTM)\r\n","\r\n","이번 챕터에서는 개체명 인식 데이터에 대한 전처리를 진행하고, 양방향 LSTM을 이용하여 개체명 인식기를 만든다. 그리고 F1-Score를 사용하여 모델을 평가한다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"AFEoVvMRpuAQ"},"source":["### 1.실습을 진행하기 전에\r\n","\r\n","* CRF layer는 현재 텐서플로우 1.14.0 버전과 케라스 2.2.4에서 가장 원활하게 동작한다. 텐서플로우와 케라스 버전을 높이면 CRF layer가 동작하지 않거나, mask_zero = True가 되지 않는 등의 문제가 발생한다. 그러므로 우선 버전을 맞춰주자. 로컬 환경의 버전은 건드리지 않기 위해 구글 Colab에서의 실습을 권장한다.\r\n"]},{"cell_type":"code","metadata":{"id":"-HafwR8zpuC5"},"source":["!pip install tensorflow==1.14.0\r\n","!pip install keras==2.2.4\r\n","!pip install tensorflow-gpu==1.14.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cPzvEK1gpuFC"},"source":["CRF를 사용하기 위해 keras_contrib를 설치해야 한다. 아래의 명령을 수행하여 설치한다.\r\n"]},{"cell_type":"code","metadata":{"id":"e4MR-IdCpuHM"},"source":["!pip install git+https://www.github.com/keras-team/keras-contrib.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zUlScc-jpuJP"},"source":["### 2.개체명 인식 데이터에 대한 이해와 전처리\r\n","\r\n","이번에는 양방향 LSTM과 CRF를 함께 사용하여 앞서 사용한 데이터 외에 다른 데이터를 사용하여 개체명 인식을 수행해보도록 하겠다. 데이터는 아래의 링크에서 다운로드 가능하다.\r\n","\r\n","링크 : https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iWPbOafppuLl","executionInfo":{"status":"ok","timestamp":1611321822140,"user_tz":-540,"elapsed":294655,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"1306a797-7c17-45f8-ae35-6be965ba5cc1"},"source":["# Google Drive Mount\r\n","from google.colab import drive\r\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RqPbJH3puN_","executionInfo":{"status":"ok","timestamp":1611321822141,"user_tz":-540,"elapsed":294645,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"5a5b0bc4-1bff-40c4-aa7e-cad6d2f81701"},"source":["cd drive/My Drive/데이터"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/데이터\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9JAG--CpuQS","executionInfo":{"status":"ok","timestamp":1611321822919,"user_tz":-540,"elapsed":295412,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"291a4f64-c824-4d4b-a461-db9bb95f62b8"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" _about.txt            fra-eng.zip                        ner_dataset.csv\n","\u001b[0m\u001b[01;34m'강우예측AI 데이터'\u001b[0m/   fra.txt                            ratings.txt\n"," best_model.h5         IWSLT16.TED.tst2011.en-cs.en.xml   train.txt\n"," eng_w2v               model.png                          \u001b[01;34mwikiextractor\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D-hTAA_5puSa","executionInfo":{"status":"ok","timestamp":1611321824469,"user_tz":-540,"elapsed":296951,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"79f6241a-733d-4c1f-cf6e-063391762383"},"source":["import pandas as pd\r\n","import numpy as np\r\n","%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","from tensorflow.keras.preprocessing.text import Tokenizer\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","from sklearn.model_selection import train_test_split\r\n","from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"TPimzoQ8puUn"},"source":["data = pd.read_csv('ner_dataset.csv', encoding = 'latin1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"0qKbWM16sBFw","executionInfo":{"status":"ok","timestamp":1611321826197,"user_tz":-540,"elapsed":298666,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"91b20977-396f-44a4-e877-2b0ae07fff13"},"source":["data[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"fQ-sp5VesBby"},"source":["이번에 사용할 데이터는 앞서 사용한 데이터랑 양식이 조금 다르다. 첫번째 열은 다음과 같은 패턴을 가지고 있다. Sentence: 1 있고, Null 값이 이어지다가 Sentence: 3이 나오고 다시 Null 값이 이어지다가를 반복한다. 그런데 사실 이는 하나의 문장을 여러 행으로 나눠놓은 것이다. 숫자값을 t라고 하자. 첫번째 Sentence: t부터 Null 값이 나오다가 Sentence: t+1이 나오기 전까지의 모든 데이터는 원래 하나의 행. 즉, 하나의 샘플이어야 한다. t번째 문장을 각 단어마다 각 하나의 행으로 나눠놓은 데이터이기 때문이다. 이는 뒤에서 Pandas의 fillna를 통해 하나로 묶는 작업을 해준다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nL6giS7sCAH","executionInfo":{"status":"ok","timestamp":1611321826198,"user_tz":-540,"elapsed":298655,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"623370e7-b899-46da-b4f6-78e71b04790b"},"source":["print('데이터프레임 행의 개수 : {}'.format(len(data)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["데이터프레임 행의 개수 : 1048575\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s2xITl01sCCd"},"source":["현재 data의 행의 개수는 1,048,575개이다. 하지만 뒤에서 기존에 문장 1개였던 행들을 1개의 행으로 병합하는 작업을 해야 하기 때문에 최종 샘플의 개수는 이보다 줄어들게 된다. 우선, 데이터를 좀 더 살펴보자.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cdfEPEtsCEi","executionInfo":{"status":"ok","timestamp":1611321826199,"user_tz":-540,"elapsed":298647,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"9556eb6c-6d84-4d25-ec26-f8b502e1c278"},"source":["print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["데이터에 Null 값이 있는지 유무 : True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E80lwiuKsCGo"},"source":["Sentence #열에 Null 값들이 존재하고 있으므로, isnull().values.any()를 수행하였을 때 True가 나온다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q6T92cHasCI7","executionInfo":{"status":"ok","timestamp":1611321826199,"user_tz":-540,"elapsed":298637,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"7e598a88-9949-4451-fa39-d8000faf5b2c"},"source":["print('어떤 열에 Null 값이 있는지 출력')\r\n","print('===============================')\r\n","data.isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["어떤 열에 Null 값이 있는지 출력\n","===============================\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Sentence #    1000616\n","Word                0\n","POS                 0\n","Tag                 0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"KtVvLQu6sCLD"},"source":["isnull().sum()을 수행하면 각 열마다의 Null 값의 개수를 보여준다. 다른 열은 0개인데, 오직 Sentence #열에서만 1,000,616개가 나온 것을 볼 수 있다. 전체 데이터에서 중복을 허용하지 않고, 유일한 값의 개수를 셀 수 있게 해주는 nunique()를 사용해보자.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ERTU-zlsCNY","executionInfo":{"status":"ok","timestamp":1611321826200,"user_tz":-540,"elapsed":298629,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"538aa3a7-7575-47a3-cbd1-5a60df252691"},"source":["print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\r\n","print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\r\n","print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sentence # 열의 중복을 제거한 값의 개수 : 47959\n","Word 열의 중복을 제거한 값의 개수 : 35178\n","Tag 열의 중복을 제거한 값의 개수 : 17\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"149SCL4WsCPT"},"source":["이 데이터에는 47,959개의 문장이 있으며 문장들은 35,178개의 단어를 가지고 17개 종류의 개체명 태깅을 가진다. 17개의 개체명 태깅이 전체 데이터에서 몇 개가 있는지, 개체명 태깅 개수의 분포를 확인해보도록 하겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPgqnDljsCRN","executionInfo":{"status":"ok","timestamp":1611321826201,"user_tz":-540,"elapsed":298620,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"811796c7-ff2b-4099-bebe-a32fa2555f71"},"source":["print('Tag 열의 각각의 값의 개수 카운트')\r\n","print('================================')\r\n","print(data.groupby('Tag').size().reset_index(name = 'count'))\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tag 열의 각각의 값의 개수 카운트\n","================================\n","      Tag   count\n","0   B-art     402\n","1   B-eve     308\n","2   B-geo   37644\n","3   B-gpe   15870\n","4   B-nat     201\n","5   B-org   20143\n","6   B-per   16990\n","7   B-tim   20333\n","8   I-art     297\n","9   I-eve     253\n","10  I-geo    7414\n","11  I-gpe     198\n","12  I-nat      51\n","13  I-org   16784\n","14  I-per   17251\n","15  I-tim    6528\n","16      O  887908\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6PpQKFMluBcf"},"source":["BIO 표현 방법에서 아무런 태깅도 의미하지 않은 O가 887,908개로 가장 많은 개수를 차지함을 볼 수 있다. 이제 데이터를 원하는 형태로 가공해보겠다. 우선 Null 값을 제거한다.\r\n"]},{"cell_type":"code","metadata":{"id":"YuXvvcCIvbR6"},"source":["data = data.fillna(method = 'ffill')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-wrJMLXvbUp"},"source":["Pandas의 (method = 'ffill')는 Null 값을 가진 행의 바로 앞의 행의 값으로 Null 값을 채우는 작업을 수행한다. 이렇게 하면 t번째 문장에 속하면서 Null 값을 가진 샘플들은 전부 첫번째 열에 Sentence: t의 값이 들어간다. 이번에는 뒤의 5개의 샘플을 출력해서 정상적으로 수행되었는지 확인해보자.\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vz8A-WL9vbZc","executionInfo":{"status":"ok","timestamp":1611321826202,"user_tz":-540,"elapsed":298606,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"9508f0db-11c9-4f8e-e38a-93a12ee650a1"},"source":["print(data.tail())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              Sentence #       Word  POS Tag\n","1048570  Sentence: 47959       they  PRP   O\n","1048571  Sentence: 47959  responded  VBD   O\n","1048572  Sentence: 47959         to   TO   O\n","1048573  Sentence: 47959        the   DT   O\n","1048574  Sentence: 47959     attack   NN   O\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N21-wciIvbby"},"source":["뒤의 5개 샘플의 첫번째 열이 Sentence: 47959로 채워졌다. 이는 47,959번째 문장임을 의미하며, Null 값을 가진 행들의 바로 앞 행의 Sentence # 열의 값이 Sentence: 47959이었음을 의미한다. 전체 데이터에 Null 값이 존재하는지 확인해보자.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLx4Izfsvbew","executionInfo":{"status":"ok","timestamp":1611321827242,"user_tz":-540,"elapsed":299636,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"35590cc7-a8de-4853-a478-129f2966d622"},"source":["print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["데이터에 Null 값이 있는지 유무 : False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ffo-yye3vbig"},"source":["없는 것으로 나온다. 모든 단어를 소문자화하여 단어의 개수를 줄여보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0V79_tcvblP","executionInfo":{"status":"ok","timestamp":1611321827242,"user_tz":-540,"elapsed":299627,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"b41f97d0-6730-4195-fdc8-2a4cda38d7f4"},"source":["data['Word'] = data['Word'].str.lower()\r\n","print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Word 열의 중복을 제거한 값의 개수 : 31817\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y69AqHD-vbni"},"source":["정상적으로 소문자화가 되었는지 앞의 샘플 5개만 출력해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPhZ9VPLvbqX","executionInfo":{"status":"ok","timestamp":1611321827242,"user_tz":-540,"elapsed":299617,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"a9809ac8-e0f6-4be3-9210-3ed98a47c606"},"source":["print(data[:5])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      thousands  NNS   O\n","1  Sentence: 1             of   IN   O\n","2  Sentence: 1  demonstrators  NNS   O\n","3  Sentence: 1           have  VBP   O\n","4  Sentence: 1        marched  VBN   O\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F2LeBvLXvbs5"},"source":["이제 하나의 문장에 등장한 단어와 개체명 태깅 정보끼리 쌍(pair)으로 묶는 작업을 수행한다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9_EzpMfvbva","executionInfo":{"status":"ok","timestamp":1611321830526,"user_tz":-540,"elapsed":302891,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"62944041-db58-4373-dcb3-bac0db9d158e"},"source":["func = lambda temp: [(w, t) for w, t in zip(temp['Word'].values.tolist(),\r\n","                                            temp['Tag'].values.tolist())]\r\n","tagged_sentences = [t for t in data.groupby('Sentence #').apply(func)]\r\n","print('전체 샘플 개수 : {}'.format(len(tagged_sentences)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["전체 샘플 개수 : 47959\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GTKU8m6zvbxj"},"source":["1,000,616개의 행의 개수가 각 문장 당 하나의 샘플로 묶이면서 47,959개의 샘플로 변환된 것을 확인할 수 있다. 정상적으로 수행이 되었는지 첫번째 샘플에 대해서 출력을 해보자.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_rzqa995HTG","executionInfo":{"status":"ok","timestamp":1611321830527,"user_tz":-540,"elapsed":302883,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"45c0374d-e1d1-40eb-c9d7-15c1d4be0ce7"},"source":["print(tagged_sentences[0]) # 첫번째 샘플 출력"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cMREJjxe5HVw"},"source":["전처리가 수행된 첫번째 샘플이 출력된 것을 볼 수 있다. 이러한 샘플이 총 47,959개가 있다. 그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 개체명 태깅 정보에 해당되는 부분을 분리시켜야 한다. 즉, [('thousands', 'O'), ('of', 'O')]와 같은 문장 샘플이 있다면 thousands와 of는 같이 저장하고, O와 O를 같이 저장할 필요가 있다.\r\n","\r\n","이런 경우 파이썬 함수 중에서 zip() 함수가 유용한 역할을 한다. zip() 함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 한다. (2챕터의 데이터의 분리 챕터 참고)\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"QU_ApJ3_5HYY"},"source":["sentences, ner_tags = [], []\r\n","\r\n","for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.\r\n","\r\n","    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에, 개체명 태깅 정보들은 tag_info에 저장.\r\n","\r\n","    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\r\n","    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GUd82jCd5Ha6"},"source":["각 문장 샘플에 대해서 단어는 sentences에, 태깅 정보는 ner_tags에 저장하였다. 임의로 첫번째 문장 샘플을 출력해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-jg8n0Tf5Hdr","executionInfo":{"status":"ok","timestamp":1611321830529,"user_tz":-540,"elapsed":302869,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"b6ce4846-1271-44b6-f9f5-7480733ba5f6"},"source":["print(sentences[0])\r\n","print(ner_tags[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n","['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9bNbasot5HiC"},"source":["첫번째 샘플에 대해서 단어에 대해서만 sentences[0]에, 또한 개체명에 대해서만 ner_tags[0]에 저장된 것을 볼 수 있다. 뒤에서 보겠지만, sentences는 예측을 위한 X에 해당되며 ner_tags는 예측 대상인 y에 해당된다. 다른 샘플들에 대해서도 처리가 되었는지 확인하기 위해 임의로 99번째 샘플에 대해서도 확인해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQrFDgw45Hk2","executionInfo":{"status":"ok","timestamp":1611321830529,"user_tz":-540,"elapsed":302859,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"2f094e62-e808-4296-d1d8-1500465d8ea4"},"source":["print(sentences[98])\r\n","print(ner_tags[98])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['she', 'had', 'once', 'received', 'a', 'kidney', 'transplant', '.']\n","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HHEbhe7X5Hmw"},"source":["단어에 대해서만 sentences[98]에, 또한 개체명에 대해서만 ner_tags[98]에 저장된 것을 확인할 수 있다. 또한 첫번째 샘플과 길이가 다른 것을 볼 수 있다. 사실 47,959개의 문장 샘플의 길이는 전부 제각각이다. 전체 데이터의 길이 분포를 확인해보자.\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"id":"Rcb9OHp07I7G","executionInfo":{"status":"ok","timestamp":1611321830529,"user_tz":-540,"elapsed":302848,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"5f2dc969-0964-4b50-d065-e0183d823c70"},"source":["print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\r\n","print('샘플의 평균 길이 : %f' % (sum(map(len, sentences)) / len(sentences)))\r\n","\r\n","plt.style.use(['seaborn-white'])\r\n","plt.hist([len(s) for s in sentences], bins = 50)\r\n","plt.xlabel('length of samples')\r\n","plt.ylabel('number of samples')\r\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["샘플의 최대 길이 : 104\n","샘플의 평균 길이 : 21.863988\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEDCAYAAADayhiNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df1TUdb7H8ecwMMtasIoxuZgram22QbDkjyOmaaIhaosZJj/WtixrtbJzWZXQ2+3XXdDE64/c7ZeWq25RaC3+WHV1sdWVuNtO18SrJ7VM08CZRFEEGYbv/cP83khodGMGgdfjHE/z/cx8v/P+NJx5nc/n853v12IYhoGIiAgQ0NIFiIjIlUOhICIiJoWCiIiYFAoiImJSKIiIiCmwpQv4V9XU1FBaWkp4eDhWq7WlyxERaRU8Hg9Op5OoqCiCg4Mvet5noVBSUsK0adO44YYbAPjpT3/Kgw8+yIwZM/B4PISHh/PCCy9gs9koLCxk+fLlBAQEMH78eFJSUnC73WRlZXHs2DGsVis5OTl069bNPH5paSnp6em+Kl9EpE1btWoVffr0uajdpyOFfv36sWjRInP7ySefJC0tjZEjRzJ//nwKCgpITk5myZIlFBQUEBQUxD333MPw4cMpKioiNDSUvLw8duzYQV5eHgsWLDCPFR4ebnasS5cuvuyGiEibUVZWRnp6uvkd+m1+nT4qKSnhmWeeAWDo0KEsW7aMHj16EB0dTUhICABxcXE4HA6Ki4tJTk4GID4+nuzs7AbHujBl1KVLF6677jo/9kJEpPVratrdp6Fw4MABHnnkEU6dOsWjjz5KdXU1NpsNgM6dO+N0OnG5XISFhZn7hIWFXdQeEBCAxWKhtrbW3F9ERJqfz0IhMjKSRx99lJEjR3LkyBEmTpyIx+Mxn2/q6hqX2y4iIs3HZ6ekXnvttSQlJWGxWPjJT37CNddcw6lTp6ipqQGgvLwcu92O3W7H5XKZ+x0/ftxsdzqdALjdbgzD0ChBRMTHfBYKhYWFLF26FACn08lXX33F3XffzaZNmwDYvHkzgwYNIiYmht27d1NZWUlVVRUOh4M+ffowcOBANm7cCEBRURH9+/f3VakiIvI1n00f3XHHHfzmN79h69atuN1unn76aW666SZmzpxJfn4+ERERJCcnExQURGZmJpMmTcJisTB16lRCQkJISkpi586dpKamYrPZyM3N9VWpIiLyNUtrvXT2F198wbBhw9i6davOPhIRuUTevjt1mQsRETG12stcSNMis9Y32n4od5SfKxGR1kYjBRERMSkURETEpFAQERGTQkFEREwKBRERMenso3ZEZyWJiDcaKYiIiEmhICIiJoWCiIiYFAoiImJSKIiIiEmhICIiJp2S2oo1dYqpiMi/SiMFERExKRRERMSkUBAREZPWFESXvxARk0YKIiJiUiiIiIhJoSAiIiaFgoiImBQKIiJiUiiIiIhJoSAiIiaFgoiImBQKIiJiUiiIiIhJoSAiIiaFgoiImBQKIiJiUiiIiIhJoSAiIiafhkJNTQ0JCQmsWbOGL7/8kl/+8pekpaUxbdo0amtrASgsLGTcuHGkpKTwzjvvAOB2u8nMzCQ1NZWMjAyOHDniyzJFRORrPg2F3//+9/zoRz8CYNGiRaSlpfHHP/6R7t27U1BQwNmzZ1myZAlvvPEGK1asYPny5Zw8eZJ169YRGhrKm2++ySOPPEJeXp4vyxQRka/5LBQOHjzIgQMHGDJkCAAlJSUMGzYMgKFDh1JcXMyuXbuIjo4mJCSE4OBg4uLicDgcFBcXM3z4cADi4+NxOBy+KlNERL7BZ6EwZ84csrKyzO3q6mpsNhsAnTt3xul04nK5CAsLM18TFhZ2UXtAQAAWi8WcbhIREd/xSSi89957xMbG0q1bt0afNwyjWdpFRKR5BfrioNu2bePIkSNs27aNsrIybDYbHTp0oKamhuDgYMrLy7Hb7djtdlwul7nf8ePHiY2NxW6343Q66d27N263G8MwzFFGexSZtb6lSxCRdsInI4UFCxawevVq3n77bVJSUpgyZQrx8fFs2rQJgM2bNzNo0CBiYmLYvXs3lZWVVFVV4XA46NOnDwMHDmTjxo0AFBUV0b9/f1+UKSIi3+KTkUJjHnvsMWbOnEl+fj4REREkJycTFBREZmYmkyZNwmKxMHXqVEJCQkhKSmLnzp2kpqZis9nIzc31V5kiIu2az0PhscceMx+//vrrFz2fmJhIYmJigzar1UpOTo6vSxMRkW/RL5pFRMSkUBAREZPf1hSk9fmus54O5Y7yYyUi4i8aKYiIiEmhICIiJoWCiIiYFAoiImJSKIiIiEmhICIiJoWCiIiYFAoiImJSKIiIiEmhICIiJoWCiIiYFAoiImK6pFCora0F4NSpU+zdu9enBYmISMvxepXU5557jqioKAYPHsx9991HbGwsAQEBPPvss/6or13RvZhFpKV5HSns27ePsWPHsm7dOu655x6ef/55jhw54o/aRETEz7yGQm1tLeXl5RQWFpKYmEhdXR2VlZX+qE1ERPzMayikp6fz0EMPceedd9KlSxcWL17MnXfe6Y/aRETEz7yuKSQnJ5OcnExdXR0ATzzxBBaLxeeFiYiI/3kdKZSUlHDXXXcxevRoABYsWMD27dt9XpiIiPif11BYtGgRy5cvJzw8HICJEyfy4osv+rwwERHxP6+hEBgYSKdOncwpo86dO2v6SESkjfK6pnDdddexcOFCKioq2LBhA1u2bOH666/3R20iIuJnl/TjtbVr13Lrrbfy0UcfcccddzBy5Eh/1CYiIn7WZCi8//775uOOHTsydOhQc3vHjh3cfvvtvq1MRET8rslQ2Lhx43fuqFAQEWl7mgyFnJwc8/G+ffv47LPPCAgI4Prrr6dXr15+KU5ERPzL65rCs88+y+7du4mJiaG+vp5XXnmFW2+9lezsbH/UJyIifuQ1FD7++GMKCgrM7fr6eiZMmODTokREpGV4/Z1CZGQk5eXl5vaJEyd0SqqISBvldaRw6NAhEhISiIyMpL6+nsOHD9OjRw/GjRuHxWJpMIqQ9qOpez8cyh3l50pEpDl5DYWFCxf6ow4REbkCeA2Fr776ivXr13P69GkMwzDbv3l2UmOqq6vJysriq6++4ty5c0yZMoXevXszY8YMPB4P4eHhvPDCC9hsNgoLC1m+fDkBAQGMHz+elJQU3G43WVlZHDt2DKvVSk5ODt26dfv+PRYRkSZ5DYXp06fz0EMPcc0111zWgYuKioiKiuKhhx7i6NGjPPDAA8TFxZGWlsbIkSOZP38+BQUFJCcns2TJEgoKCggKCuKee+5h+PDhFBUVERoaSl5eHjt27CAvL48FCxb8yx0VERHvvIZCz549zfWDy5GUlGQ+/vLLL7n22mspKSnhmWeeAWDo0KEsW7aMHj16EB0dTUhICABxcXE4HA6Ki4tJTk4GID4+XqfAioj4gddQGD16NMnJydx4441YrVaz3dv00QUTJkygrKyMl156ifvvvx+bzQacv9qq0+nE5XIRFhZmvj4sLOyi9oCAACwWC7W1teb+IiLS/LyGwoIFC5g8ebJ5P4XL9dZbb7F3716mT5/eYE3im4+/6XLbRUSk+XgNhV69epGSknLZBy4tLaVz5878+Mc/5qabbsLj8XDVVVdRU1NDcHAw5eXl2O127HY7LpfL3O/48ePExsZit9txOp307t0bt9uNYRgaJYiI+JjXUOjUqRPp6elERUU1mD6aMWPGd+734YcfcvToUWbNmoXL5eLs2bMMGjSITZs28Ytf/ILNmzczaNAgYmJimD17NpWVlVitVhwOB9nZ2Zw5c4aNGzcyaNAgioqK6N+///fvrYiIfCevodCvXz/69evXoK2urs7rgSdMmMCsWbNIS0ujpqaGp556iqioKGbOnEl+fj4REREkJycTFBREZmYmkyZNwmKxMHXqVEJCQkhKSmLnzp2kpqZis9nIzc3913spIiKXxGJcwmT9/v37OXnyJAC1tbXk5uaydu1anxf3Xb744guGDRvG1q1bue6661q0lubS1K+EWxP9olnkyubtu9PrSOGpp57i008/5dNPP+WWW26htLSUBx980CfFiohIy/J6QbwDBw6wcuVKevXqxUsvvcQ777zDwYMH/VGbiIj4mddQ8Hg8nDlzBjh/hdQf//jH7Nu3z+eFiYiI/3mdPsrIyODPf/4zGRkZjBkzhsDAQOLj4/1RW5vVFtYORKRt8hoKY8aMMR/fcccdVFVV0bFjR58WJSIiLcNrKLzyyiuEhoYyevRoJk6cSMeOHYmNjeXxxx/3R30iIuJHXtcU/vrXvzJhwgQ2bNjAsGHDWLZsGQ6Hwx+1iYiIn3kNhfr6eurr61m7dq155dOqqiqfFyYiIv7nNRQSEhIYOHAg119/PT169GDJkiXExMT4ozYREfEzr2sKkydPZvLkyeb2fffdx9VXX+3TokREpGV4HSl8mwJBRKTtuuxQEBGRtqvJUPiv//qvBv8VEZG2r8k1ha1bt3Lw4EEcDgeHDh266PmFCxf6si4REWkBTYbCihUrOHDgAMeOHSM9Pd2fNYmISAtpcvqoU6dO9O3blzVr1gDwv//7v+zbt4/AwMCLbrojIiJtg9eF5t/+9rcsW7YMwzCoqanhd7/7ndYZRETaKK+/U9izZw+rVq0ytydPnkxGRoZPixIRkZbhNRTq6uqoqakhODgYgLNnz+LxeHxemLROTV0WXLfpFGkdvIbCfffdx1133UVkZCT19fUcPnyYGTNm+KM2ERHxM6+hkJSUxJAhQzh06BAWi4XIyEh++MMf+qM2ERHxM6+hANChQwd+9rOf+boWERFpYbrMhYiImLyGwurVq/1Rh4iIXAG8hsLf//53Dh486I9aRESkhXldUygtLWXMmDF06NCBoKAgDMPAYrFQXFzsj/pERMSPvIbC5s2b/VGHiIhcAbxOH5WVlfHv//7vPP744wCsX7+eo0eP+rwwERHxP6+hMGvWLBISEjhx4gQAYWFhZGVl+bwwERHxP6+hUF9fz+23347FYgFgwIABGIbh88JERMT/vK4pBAYGUlxcTH19PS6Xi7/85S/84Ac/8EdtrV5T1wESEblSeR0p/Od//ifr1q2joqKCBx98kL1795KTk+OP2kRExM+8jhTsdjv33XcfgwcPxmKx0KtXL+x2uz9qExERP/MaCk899RR79+4lOjoawzB45ZVXiIuLIzs72+vB586dyz//+U/q6up4+OGHiY6OZsaMGXg8HsLDw3nhhRew2WwUFhayfPlyAgICGD9+PCkpKbjdbrKysjh27BhWq5WcnBy6devWLJ0WEZHGeQ2FvXv38s4775jb9fX1TJgwweuBP/jgA/bv309+fj4VFRWMHTuWAQMGkJaWxsiRI5k/fz4FBQUkJyezZMkSCgoKCAoK4p577mH48OEUFRURGhpKXl4eO3bsIC8vjwULFny/3oqIyHfyuqbQo0cPysvLze0TJ05www03eD1w3759WbhwIQChoaFUV1dTUlLCsGHDABg6dCjFxcXs2rWL6OhoQkJCCA4OJi4uDofDQXFxMcOHDwcgPj4eh8PxL3VQREQuXZMjhXHjxmGxWHC73QwbNozu3bsDcPjwYW666SavB7ZarXTo0AGAgoICBg8ezI4dO7DZbAB07twZp9OJy+UiLCzM3C8sLOyi9oCAACwWC7W1teb+IiLS/JoMhUWLFjXLG2zZsoWCggKWLVvGiBEjzPamfutwue0iItJ8mgyFrl27AvDxxx+zfv16Tp8+3eCL+VJOS92+fTsvvfQSr732GiEhIXTo0MG833N5eTl2ux273Y7L5TL3OX78OLGxsdjtdpxOJ71798btdmMYhkYJIiI+5nVNYfr06dxwww2MGDGCO++80/znzenTp5k7dy4vv/wyHTt2BM6vDWzatAk4f6G9QYMGERMTw+7du6msrKSqqgqHw0GfPn0YOHAgGzduBKCoqIj+/ft/n36KiMgl8Hr2Uc+ePc31hcuxYcMGKioqeOKJJ8y23NxcZs+eTX5+PhERESQnJxMUFERmZiaTJk3CYrEwdepUQkJCSEpKYufOnaSmpmKz2cjNzb383omIyGXxGgqjR48mOTmZG2+8EavVarZ7mz669957uffeey9qf/311y9qS0xMJDExsUHbhd8miIiI/3gNhQULFjB58mTCw8P9UY+IiLQgr6HQq1cvUlJS/FGLiIi0MK+h0KlTJ9LT04mKimowfTRjxgyfFiYiIv7nNRT69etHv379/FGLiIi0MK+hAFz2mUciItI6eQ2FTz75xHxcV1fHrl27uOGGG0hOTvZpYdI+NHUjokO5o/xciYjAJYTCzJkzG2x7PB4ef/xxnxUkIiItx2soVFdXN9h2Op18+umnPitIRERajtdQGDXq/4fxFouFkJAQHnjgAZ8WJW2P7lct0jp4DYW//vWv/qhDRESuAF5DYfXq1axcufKiq6Ru3brVp4WJiIj/eQ2FpUuX8uKLL9KlSxd/1CMiIi3IayhERkbSs2dPf9QiIiItzGsohIWFce+99xIbG6vLXIiItHFeQ+HWW2/l1ltv9UctIiLSwryGwtixY/1Rh4iIXAG83o5TRETaD4WCiIiYFAoiImJSKIiIiEmhICIiJoWCiIiYLunOa/LddAVQEWkrNFIQERGTQkFEREwKBRERMSkURETEpFAQERGTQkFEREwKBRERMSkURETEpFAQERGTQkFEREwKBRERMfk0FD755BMSEhJYuXIlAF9++SW//OUvSUtLY9q0adTW1gJQWFjIuHHjSElJ4Z133gHA7XaTmZlJamoqGRkZHDlyxJeliogIPgyFs2fP8txzzzFgwACzbdGiRaSlpfHHP/6R7t27U1BQwNmzZ1myZAlvvPEGK1asYPny5Zw8eZJ169YRGhrKm2++ySOPPEJeXp6vShURka/5LBRsNhuvvvoqdrvdbCspKWHYsGEADB06lOLiYnbt2kV0dDQhISEEBwcTFxeHw+GguLiY4cOHAxAfH4/D4fBVqSIi8jWfhUJgYCDBwcEN2qqrq7HZbAB07twZp9OJy+UiLCzMfE1YWNhF7QEBAVgsFnO6SUREfKPFFpoNw2iWdhERaT5+DYUOHTpQU1MDQHl5OXa7HbvdjsvlMl9z/Phxs93pdALnF50NwzBHGSIi4ht+DYX4+Hg2bdoEwObNmxk0aBAxMTHs3r2byspKqqqqcDgc9OnTh4EDB7Jx40YAioqK6N+/vz9LFRFpl3x2O87S0lLmzJnD0aNHCQwMZNOmTcybN4+srCzy8/OJiIggOTmZoKAgMjMzmTRpEhaLhalTpxISEkJSUhI7d+4kNTUVm81Gbm6ur0oVEZGv+SwUoqKiWLFixUXtr7/++kVtiYmJJCYmNmizWq3k5OT4qjwREWmEftEsIiImhYKIiJgUCiIiYlIoiIiISaEgIiImhYKIiJgUCiIiYvLZ7xTaosis9S1dgoiIT2mkICIiJoWCiIiYNH0kV6SmpuoO5Y7ycyUi7YtGCiIiYlIoiIiISaEgIiImhYKIiJgUCiIiYlIoiIiISaekSquiU1VFfEsjBRERMSkURETEpFAQERGTQkFEREwKBRERMSkURETEpFAQERGTQkFEREz68Zq0CfpRm0jz0EhBRERMCgURETEpFERExKQ1hUY0NT8trY/WGkQuj0YKIiJiUiiIiIhJ00fSLmlaSaRxV3Qo/Pa3v2XXrl1YLBays7O55ZZbWrokaeMUFtLeXbGh8N///d98/vnn5Ofnc/DgQbKzs8nPz2/psqSd+q6TDxQY0pZcsaFQXFxMQkICAL169eLUqVOcOXOGq6++GgCPxwNAWVlZ87951YnmP6a0WZGPrWi0fcfMoY223zan6LJeL9KcLnxnXvgO/bYrNhRcLhc333yzuR0WFobT6TRDwel0ApCent7s7/2DZj+itEfDNj/faHtTf19NvV7EF5xOJ927d7+o/YoNhW8zDKPBdlRUFKtWrSI8PByr1dpCVYmItC4ejwen00lUVFSjz1+xoWC323G5XOb28ePHCQ8PN7eDg4Pp06dPS5QmItKqNTZCuOCK/Z3CwIED2bRpEwB79uzBbrebU0ciIuIbV+xIIS4ujptvvpkJEyZgsVj4j//4j+91vPZweuvcuXP55z//SV1dHQ8//DDR0dHMmDEDj8dDeHg4L7zwAjabraXLbBY1NTWMHj2aKVOmMGDAgDbbT4DCwkJee+01AgMDefzxx7nxxhvbZH+rqqqYOXMmp06dwu12M3XqVMLDw3n66acBuPHGG3nmmWdatsjv6ZNPPmHKlCn86le/IiMjgy+//LLRz7KwsJDly5cTEBDA+PHjSUlJ8V+RRjtQUlJiTJ482TAMwzhw4IAxfvz4Fq6o+RUXFxsPPvigYRiGceLECeP22283srKyjA0bNhiGYRh5eXnGqlWrWrLEZjV//nzj7rvvNlavXt2m+3nixAljxIgRxunTp43y8nJj9uzZbba/K1asMObNm2cYhmGUlZUZd955p5GRkWHs2rXLMAzD+Ld/+zdj27ZtLVni91JVVWVkZGQYs2fPNlasWGEYhtHoZ1lVVWWMGDHCqKysNKqrq41Ro0YZFRUVfqvzip0+ak5Nnd7alvTt25eFCxcCEBoaSnV1NSUlJQwbNgyAoUOHUlxc3JIlNpuDBw9y4MABhgwZAtBm+wnn/3YHDBjA1Vdfjd1u57nnnmuz/e3UqRMnT54EoLKyko4dO3L06FFzVN/a+2qz2Xj11Vex2+1mW2Of5a5du4iOjiYkJITg4GDi4uJwOBx+q7NdhILL5aJTp07m9oXTW9sSq9VKhw4dACgoKGDw4MFUV1eb0wqdO3duM32eM2cOWVlZ5nZb7SfAF198QU1NDY888ghpaWkUFxe32f6OGjWKY8eOMXz4cDIyMpgxYwahoaHm8629r4GBgQQHBzdoa+yzdLlchIWFma/x9/fVFbum4EvGt05vbUu2bNlCQUEBy5YtY8SIEWZ7W+nze++9R2xsLN26dWv0+bbSz286efIkL774IseOHWPixIkN+tiW+vunP/2JiIgIli5dyr59+5g6dSohISHm822pr41pqn/+7ne7CAVvp7e2Fdu3b+ell17itddeIyQkhA4dOlBTU0NwcDDl5eUNhq2t1bZt2zhy5Ajbtm2jrKwMm83WJvt5QefOnfn5z39OYGAgP/nJT7jqqquwWq1tsr8Oh4PbbrsNgN69e3Pu3Dnq6urM59tSXy9o7G+3se+r2NhYv9XULqaP2sPpradPn2bu3Lm8/PLLdOzYEYD4+Hiz35s3b2bQoEEtWWKzWLBgAatXr+btt98mJSWFKVOmtMl+XnDbbbfxwQcfUF9fT0VFBWfPnm2z/e3evTu7du0C4OjRo1x11VX06tWLDz/8EGhbfb2gsc8yJiaG3bt3U1lZSVVVFQ6Hw6+/ybIYbX1M9rV58+bx4Ycfmqe39u7du6VLalb5+fksXryYHj16mG25ubnMnj2bc+fOERERQU5ODkFBQS1YZfNavHgxXbt25bbbbmPmzJlttp9vvfUWBQUFAPz6178mOjq6Tfa3qqqK7OxsvvrqK+rq6pg2bRrh4eE89dRT1NfXExMTw5NPPtnSZf7LSktLmTNnDkePHiUwMJBrr72WefPmkZWVddFnuXHjRpYuXYrFYiEjI4O77rrLb3W2m1AQERHv2sX0kYiIXBqFgoiImBQKIiJiUiiIiIhJoSAiIiaFgrRaa9asYc6cOc1yrDNnzrBjxw7g/KmuK1euvOxjlJSUMGLECP785z83S02X6o477qCqqsqv7yltl0JBhPM/avz73//+vY7xj3/8g7S0NEaOHNlMVYn4X7u4zIW0fatWrWLt2rUEBASQkJDAAw88wOLFizl9+jSfffYZhw8fJjs7m9tvv51XXnmF9evX061bN+rq6rj//vt59tlnOXPmDJGRkcD5694//PDDHDp0iFmzZjF48OAG7zd37lwcDgcej4f09HRuuukm1qxZQ2BgIHa7naSkJADcbjfTp0/H6XRSW1vLY489xuDBg8nJyeHjjz/m3LlzpKamkpKSQlZWFmFhYezZs4cTJ07w0EMPsWbNGioqKli5ciV/+ctf2L59O2fOnKGsrIxf/epXjBs3zqypvLycWbNm4Xa7sVqtPP/880RERPD8889TWlqKx+MhNTWVu+++22+fi7Q+CgVp9Y4cOcLGjRt58803AUhNTSUxMRGAsrIyXn31Vf72t7/x1ltvERMTw6pVq9i0aRNnzpxhxIgR3H///UyaNIn9+/dz7733snjxYk6ePMnLL7/M9u3befPNNxuEwj/+8Q/279/PW2+9xdmzZ7nrrrt47733GDt2LJ06dTIDAc6HS0VFBatWraKyspL333+fc+fO0bVrV5588klqampISEgwb6ISGBjI8uXLyczM5KOPPuKNN95g+vTplJSUAHDgwAHeffddKisr+cUvfsHYsWPN91q4cCEPPPAA8fHxvP/++/zud7/jN7/5Ddu2bWPLli243W7effddn38e0ropFKTV2717N59//jkTJ04Ezl8u4ejRo8D5O/gBdOnShdOnT3P48GF++tOfEhwcTHBwcJN34Luw37XXXsvp06cbPFdaWkrfvn2B8xc0u/766/n8888bPU7Pnj2pqqpi+vTpDB8+nFGjRhEQEMCpU6eYMGECQUFBVFRUmK+/UI/dbqdnz54AXHPNNWYNffv2JTAwkLCwMH70ox812Pejjz7is88+4/e//z0ej4ewsDA6duxIZGQkv/71r0lMTCQ5Ofky/s9Ke6RQkFYvKCiIIUOG8OyzzzZo/+CDDwgMbPgnbhgGAQH/v5RmsVgaPea39/umb+/jdrsbHPObfvjDH/L222/jcDh49913KSoqYuzYsXzwwQesWLGCoKAgfv7zn5uvt1qtjT6+cDWa+vr6Bm3frCUoKIiFCxdedCXR1157jT179rBu3Tr+9Kc/sWzZsib7JqKFZmn1br75ZkpKSqiursYwDJ5//nlqamoafW3Xrl3Zv38/brebEydOUFpaCkBAQECDyzR/lzZ9LV0AAAGOSURBVKioKHM6p6qqisOHD9O9e/dGX7tnzx7Wrl1Lnz59ePrppzl48CAVFRV06dKFoKAgtm7disfjoba29pLe+3/+53/weDycOHGCqqoq84q4ADExMWzZsgU4f8e2tWvX8sUXX/CHP/yBm2++mZkzZ5p3NhNpikYK0upFREQwceJE0tPTsVqtJCQkXHSHqwuuueYaRo8eTUpKCr169eKWW27BarXys5/9jHnz5tGlSxev79enTx+ioqJIT0+nrq6OzMxM865333bdddcxf/588vPzsVqtTJo0ifj4eF599VUyMjJISEhgyJAh5s3pvenatSvTpk3j888/54knnmgwQnn00UfJzs5m/fr1WCwWcnJysNvtfPTRR2zYsIGgoKAGC9MijdFVUqXdWbNmDaNHjyYwMJAxY8awdOnSSwqDlrZmzRr279/PzJkzW7oUacM0UpB2x+VyMX78eGw2G2PGjGkVgSDiLxopiIiISQvNIiJiUiiIiIhJoSAiIiaFgoiImBQKIiJiUiiIiIjp/wAEZ6pRXYUSowAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"nfBA5SL97I9x"},"source":["위의 그래프는 샘플들의 길이가 대체적으로 0~40의 길이를 가지는 것을 보여준다. 길이가 가장 긴 샘플의 길이는 104이다. 이제 케라스 토크나이저를 통해서 정수 인코딩을 진행한다. 이번에는 문장 데이터에 있는 모든 단어를 사용하겠다.\r\n"]},{"cell_type":"code","metadata":{"id":"Ehtggy-Y7I_9"},"source":["src_tokenizer = Tokenizer(oov_token = 'OOV') # 모든 단어를 사용하지만 인덱스 1에는 단어 'OOV'를 할당한다.\r\n","src_tokenizer.fit_on_texts(sentences)\r\n","tar_tokenizer = Tokenizer(lower = False) # 태깅 정보들은 내부적으로 대문자를 유지한채로 저장\r\n","tar_tokenizer.fit_on_texts(ner_tags)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"evtZDY5e7JCu"},"source":["문장 데이터에 대해서는 src_tokenizer를, 레이블에 해당되는 개체명 태깅 정보에 대해서는 tar_tokenizer를 사용한다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sM4BzOYr7JFB","executionInfo":{"status":"ok","timestamp":1611321831799,"user_tz":-540,"elapsed":304101,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"7afcd5dc-b8cb-4afb-9645-048d0698123b"},"source":["vocab_size = len(src_tokenizer.word_index) + 1\r\n","tag_size = len(tar_tokenizer.word_index) + 1\r\n","\r\n","print('단어 집합의 크기 : {}'.format(vocab_size))\r\n","print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["단어 집합의 크기 : 31819\n","개체명 태깅 정보 집합의 크기 : 18\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Cgt27nCm7JHp"},"source":["앞서 src_tokenizer를 만들 때 Tokenizer의 인자로 oov_token = 'OOV'를 선택했다. 이렇게 하면 인덱스 1에 단어 'OOV'가 할당된다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ByrpHmd97JJu","executionInfo":{"status":"ok","timestamp":1611321831799,"user_tz":-540,"elapsed":304090,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"1163c520-05c1-4c72-9ba2-4c1276b649ff"},"source":["print('단어 OOV의 인덱스 : {}'.format(src_tokenizer.word_index['OOV']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["단어 OOV의 인덱스 : 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hzgxbxpW7JMB"},"source":["이제 정수 인코딩을 수행한다.\r\n"]},{"cell_type":"code","metadata":{"id":"Wk8cTbaS7JOT"},"source":["X_train = src_tokenizer.texts_to_sequences(sentences)\r\n","y_train = tar_tokenizer.texts_to_sequences(ner_tags)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1DqbFMim7JQ1"},"source":["이제 문장 데이터에 대해서 정수 인코딩이 수행된 결과는 X_train, 개체명 태깅 데이터에 대해서 정수 인코딩이 수행된 결과는 y_train에 저장되었다. 정수 인코딩이 되었는지 확인을 위해 임의로 첫번째 샘플을 출력해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XHUzrDg7JSu","executionInfo":{"status":"ok","timestamp":1611321831800,"user_tz":-540,"elapsed":304076,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"b3e0538c-2906-4521-a162-a9edb0dc42a7"},"source":["print(X_train[0])\r\n","print(y_train[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n","[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mha-FS0i7JVH"},"source":["모델 훈련 후 결과 확인을 위해 인덱스로부터 단어를 리턴하는 index_to_word를 만든다. 그와 동시에 뒤에서 사용할 index_to_ner도 만든다. 이때, 인덱스 0은 'PAD'란 단어를 할당해두겠다. index_to_ner은 개수가 적으니 출력까지 해보자.\r\n"]},{"cell_type":"code","metadata":{"id":"VZIhWZ-A7JXh"},"source":["word_to_index = src_tokenizer.word_index\r\n","index_to_word = src_tokenizer.index_word\r\n","\r\n","ner_to_index = tar_tokenizer.word_index\r\n","index_to_ner = tar_tokenizer.index_word\r\n","\r\n","index_to_ner[0] = 'PAD'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LA5Vuspd-ppK","executionInfo":{"status":"ok","timestamp":1611321831801,"user_tz":-540,"elapsed":304047,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"211e1802-7c52-4eaa-e19c-2bb735eee1ef"},"source":["print(index_to_ner)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xtrt5Zrh-qY3"},"source":["index_to_word를 만들었으니 시험삼아 첫번째 샘플에 대해서 다시 디코딩(정수에서 다시 텍스트 데이터로 변환) 작업을 해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PBDefGT-qcJ","executionInfo":{"status":"ok","timestamp":1611321832976,"user_tz":-540,"elapsed":305204,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"8430d66a-a1e9-41d2-b098-2286465fc55e"},"source":["decoded = []\r\n","\r\n","for index in X_train[0]: # 첫번째 샘플 안의 인덱스들에 대해서\r\n","    decoded.append(index_to_word[index]) # 다시 단어로 변환\r\n","\r\n","print('기존의 문장 : {}'.format(sentences[0]))\r\n","print('디코딩 문장 : {}'.format(decoded))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["기존의 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n","디코딩 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B3POiIII-qet"},"source":["이제 X 데이터와 y 데이터가 구성되었다. 이제 패딩 작업을 진행해보자. 앞서 확인하였듯이 대부분의 데이터의 길이는 40~60에 분포되어져 있다. 그러므로 가장 긴 샘플의 길이인 104가 아니라 70정도로 max_len을 정해보겠다.\r\n"]},{"cell_type":"code","metadata":{"id":"8-K0OUZw-qho"},"source":["max_len = 70\r\n","# 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\r\n","X_train = pad_sequences(X_train, padding = 'post', maxlen = max_len)\r\n","y_train = pad_sequences(y_train, padding = 'post', maxlen = max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECzMYZdW-qjv"},"source":["모든 샘플의 길이가 70이 되었다. 이제 훈련 데이터와 테스트 데이터를 8:2의 비율로 분리한다.\r\n"]},{"cell_type":"code","metadata":{"id":"062r3o4a-qnA"},"source":["X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\r\n","                                                    test_size = 0.2,\r\n","                                                    random_state = 777)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EjEOTyKb-qt8"},"source":["레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩을 수행한다.\r\n"]},{"cell_type":"code","metadata":{"id":"xeNxEKa2-qxQ"},"source":["y_train = to_categorical(y_train, num_classes = tag_size)\r\n","y_test  = to_categorical(y_test , num_classes = tag_size)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GmFDcune-qz8"},"source":["이제 각 데이터 크기를 확인해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kvm_PD2v-q2T","executionInfo":{"status":"ok","timestamp":1611321832978,"user_tz":-540,"elapsed":305166,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"45eadb00-c6b3-4861-c6bb-7f8990c884ae"},"source":["print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\r\n","print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\r\n","\r\n","print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\r\n","print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["훈련 샘플 문장의 크기 : (38367, 70)\n","훈련 샘플 레이블의 크기 : (38367, 70, 18)\n","테스트 샘플 문장의 크기 : (9592, 70)\n","테스트 샘플 레이블의 크기 : (9592, 70, 18)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4zd4mCCA-q4Y"},"source":["### 3.F1-Score\r\n","\r\n","시퀀스 레이블링 모델을 평가할 때는 한 가지 주의할 점이 있다. 이런 모델의 경우에는 보통 큰 의미를 갖지 않는 레이블 정보가 존재한다. 예를 들어 개체명 인식에서는 그 어떤 개체도 아니라는 의미의 'O'라는 태깅이 존재한다. 그런데 이런 정보는 보통 대다수의 레이블을 차지하기 때문에 기존에 사용했던 정확도 평가 방법을 사용하는 것이 적절하지 않을 수 있다.\r\n","\r\n","예를 들어 모델이 단 1개의 개체도 맞추지 못하고 전부 'O'로 예상했을 경우를 보자. 우선 실제값은 바로 위에서 출력했던 값을 실제값으로 재사용하겠다. 아래 코드에서는 true라는 변수에 저장하였다. 그리고 개체를 하나도 맞추지 못했다는 가정하에 전부 'O'로만 채워진 예측값 predicted를 생성한다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nU0dawHrBcJr","executionInfo":{"status":"ok","timestamp":1611321832978,"user_tz":-540,"elapsed":305153,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"42353d45-5363-40d4-960a-85394df02713"},"source":["true=['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\r\n","# 실제값\r\n","\r\n","predicted=['O'] * len(true) #실제값의 길이만큼 전부 'O'로 채워진 리스트 생성. 예측값으로 사용.\r\n","print(predicted)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M05lTVL7BcMX"},"source":["실제로는 PER, MISC, PER, MISC, PER이라는 총 5개의 개체가 존재함에도 불구하고 예측값인 predicted는 단 1개의 개체도 맞추지 못한 상황을 시뮬레이션하는 것이다. 이제 이에 대한 정확도를 계산해보자.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBwuXtm4BcQS","executionInfo":{"status":"ok","timestamp":1611321832978,"user_tz":-540,"elapsed":305141,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"3a0d35f7-a307-416e-e49b-7826d79bf573"},"source":["hit = 0 # 정답 개수\r\n","for t, p in zip(true, predicted):\r\n","    if t == p:\r\n","        hit += 1 # 정답인 경우에는 +1\r\n","\r\n","accuracy = hit / len(true) # 정답 개수를 총 개수로 나눈다.\r\n","print('정확도 : {:.1%}'.format(accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["정확도 : 74.4%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WPOVyxJDBcS7"},"source":["실제값에서도 대부분의 값이 'O'이기 때문에 그 어떤 개체도 찾지 못하였음에도 74%의 정확도를 얻는다. 이는 정확도가 뻥튀기되어 모델의 성능을 오해할 수 있다는 문제가 있다. 그래서 여기서는 위와 같은 상황에서 더 적절한 평가 방법을 도입하고자 한다. 윈도우의 명령 프롬프트나 UNIX의 터미널에서 아래의 명령을 수행하여 파이썬 패키지 seqeval를 설치한다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYHPj0QMBcVO","executionInfo":{"status":"ok","timestamp":1611321836867,"user_tz":-540,"elapsed":309019,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"f610e9a2-f287-4a02-e999-b9a8633582ca"},"source":["!pip install seqeval"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\r\u001b[K     |███████▌                        | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 32.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 25.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=21368b7d067eb407a007c3efc828f3b08bb1f89d7ef5c7f186e6d235113b7c51\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ztapn8SRBcXj"},"source":["앞서 머신러닝 훑어보기 챕터에서 정밀도(precision)과 재현율(recall)을 배운 바 있다. 개체명 인식 모델의 성능 측정을 위해 정밀도와 재현률 개념을 사용해보겠다. 이를 개체명 인식 문제에 맞도록 해석해보면 다음과 같다.\r\n","\r\n","<br>\r\n","\r\n","$정밀도 = \\frac{TP}{TP + FP} = \\text{특정 개체라고 예측한 경우 중에서 실제 특정 개체로 판명되어 예측이 일치한 비율}$\r\n","\r\n","$재현률 = \\frac{TP}{TP + FN} = \\text{전체 특정 개체 중에서 실제 특정 개체라고 정답을 맞춘 비율}$\r\n","\r\n","정밀도와 재현률로부터 조화 평균(harmonic mean)을 구한 것을 F1-Score라고 한다.\r\n","\r\n","$f1\\ score = 2 × \\frac{\\text{정밀도 × 재현률}}{\\text{정밀도 + 재현률}}$\r\n","\r\n","predicted의 성능을 평가하기 위해서 정밀도, 재현률, f1-score를 계산해보도록 하겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kd42M3OuBcdq","executionInfo":{"status":"ok","timestamp":1611321836868,"user_tz":-540,"elapsed":309009,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"e3b38e57-3181-457f-b7bd-0e41f6dc388b"},"source":["from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\r\n","\r\n","print(classification_report([true], [predicted]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        MISC       0.00      0.00      0.00         2\n","         PER       0.00      0.00      0.00         3\n","\n","   micro avg       0.00      0.00      0.00         5\n","   macro avg       0.00      0.00      0.00         5\n","weighted avg       0.00      0.00      0.00         5\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"2XLhYmqkBcf8"},"source":["이러한 측정 방법을 사용하면 PER과 MISC 두 특정 개체 중에서 실제 predicted가 맞춘 것은 단 1개도 없는 것을 확인할 수 있다. 이번에는 어느 정도는 정답을 맞추었다고 가정하고 예측값인 predicted를 수정하여 정밀도, 재현률, f1-score를 확인해보자.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebzWkmDFBcia","executionInfo":{"status":"ok","timestamp":1611321836868,"user_tz":-540,"elapsed":308998,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"a72b408e-0fea-4c79-aae6-a82a7c38d895"},"source":["true=['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\r\n","predicted=['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O']\r\n","print(classification_report([true], [predicted]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        MISC       1.00      0.50      0.67         2\n","         PER       1.00      0.67      0.80         3\n","\n","   micro avg       1.00      0.60      0.75         5\n","   macro avg       1.00      0.58      0.73         5\n","weighted avg       1.00      0.60      0.75         5\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1REhB9_KBckz"},"source":["특정 개체로 예측한 경우에 대해서는 모두 제대로 예측을 하였으므로 정밀도는 1이 나온다. 하지만 재현률에서는 MISC는 실제로는 4개임에도 2개만을 맞추었으므로 0.5, PER은 실제로는 3개임에도 2개만을 맞추었으므로 0.67이 나온 것을 볼 수 있다.\r\n"]},{"cell_type":"markdown","metadata":{"id":"UKTpziKxBcmf"},"source":["### 4.F1-Score를 측정하는 콜백 클래스\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8AnReWfGfjf","executionInfo":{"status":"ok","timestamp":1611321836869,"user_tz":-540,"elapsed":308990,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"2d994adf-96cc-4e6f-d766-93a84ab9995a"},"source":["from keras.callbacks import Callback\r\n","from seqeval.metrics import f1_score, classification_report"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9SkFd7ekGfl7"},"source":["모델을 학습하는 과정에서 검증 데이터에 대한 F1-Score를 출력하기 위해 다음과 같은 클래스를 구현한다. 이렇게 클래스를 구현해두면 모델을 검증 데이터를 통해 검증하는 과정에서 F1-score를 지속적으로 확인할 수 있다. 그리고 F1-Score가 가장 높아질 때마다 모델을 저장한다.\r\n"]},{"cell_type":"code","metadata":{"id":"tQu7_9xLGfoJ"},"source":["class F1score(Callback):\r\n","\r\n","    def __init__(self, value = 0.0, use_char = True):\r\n","        super(F1score, self).__init__()\r\n","        self.value = value\r\n","        self.use_char = use_char\r\n","\r\n","    def sequences_to_tags(self, sequences): # 예측값을 index_to_ner을 사용하여 태깅 정보로 변경하는 함수.\r\n","    \r\n","        result = []\r\n","        for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\r\n","            tag = []\r\n","            for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.\r\n","                pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0, 0]이면 1의 인덱스인 2를 리턴한다.\r\n","                tag.append(index_to_ner[pred_index].replace('PAD', 'O')) # 'PAD'는 'O'로 변경\r\n","\r\n","            result.append(tag)\r\n","        return result\r\n","\r\n","    # 에포크가 끝날 때마다 실행되는 함수\r\n","    def on_epoch_end(self, epoch, logs = {}):\r\n","\r\n","        # char Embedding을 사용하는 경우\r\n","        if self.use_char:\r\n","            X_test = self.validation_data[0]\r\n","            X_char_test = self.validation_data[1]\r\n","            y_test = self.validation_data[2]\r\n","            y_predicted = self.model.predict([X_test, X_char_test])\r\n","        else:\r\n","            X_test = self.validation_data[0]\r\n","            y_test = self.validation_data[1]\r\n","            y_predicted = self.model.predict([X_test])\r\n","\r\n","        pred_tags = self.sequences_to_tags(y_predicted)\r\n","        test_tags = self.sequences_to_tags(y_test)\r\n","\r\n","        score = f1_score(pred_tags, test_tags)\r\n","        print(' - f1: {:04.2f}'.format(score * 100))\r\n","        print(classification_report(test_tags, pred_tags))\r\n","\r\n","        # F1-Score가 지금까지 중 가장 높은 경우\r\n","        if score > self.value:\r\n","            print('f1_score improved from %f to %f, saving model to best_model.h5' % (self.value, score))\r\n","            self.model.save('best_model.h5')\r\n","            self.value = score\r\n","        else:\r\n","            print('f1_score did not improve from %f' % (self.value))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tBgkWUhQGfq9"},"source":["### 5.BiLSTM을 이용한 개체명 인식기\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"EtZuRPijGfsu"},"source":["from keras.models import Sequential\r\n","from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\r\n","from keras.optimizers import Adam\r\n","from keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cp757MioOEEa","executionInfo":{"status":"ok","timestamp":1611321837912,"user_tz":-540,"elapsed":310014,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"d017792e-a223-4c18-a9bf-66cceb99e215"},"source":["model = Sequential()\r\n","model.add(Embedding(vocab_size, 128, input_length = max_len, mask_zero = True))\r\n","model.add(Bidirectional(LSTM(256, return_sequences = True)))\r\n","model.add(TimeDistributed(Dense(tag_size, activation = 'softmax')))\r\n","\r\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 70, 128)           4072832   \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 70, 512)           788480    \n","_________________________________________________________________\n","time_distributed_1 (TimeDist (None, 70, 18)            9234      \n","=================================================================\n","Total params: 4,870,546\n","Trainable params: 4,870,546\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pptaazk7OEIN","executionInfo":{"status":"ok","timestamp":1611321837913,"user_tz":-540,"elapsed":310000,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"0a736a20-dc65-499c-e9e4-a95ac1160700"},"source":["model.compile(loss = 'categorical_crossentropy',\r\n","              optimizer = Adam(0.001), metrics = ['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExAmDC7EOEKR","executionInfo":{"status":"ok","timestamp":1611323273393,"user_tz":-540,"elapsed":1745469,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"4f3d6115-52f8-4ea2-e764-ab2f8d50f880"},"source":["hist = model.fit(X_train, y_train,\r\n","                 batch_size = 128, epochs = 15,\r\n","                 validation_split = 0.1,\r\n","                 callbacks = [F1score(use_char = False)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","Train on 34530 samples, validate on 3837 samples\n","Epoch 1/15\n","34530/34530 [==============================] - 83s 2ms/step - loss: 0.5544 - acc: 0.8778 - val_loss: 0.2353 - val_acc: 0.9352\n"," - f1: 63.04\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00        37\n","         eve       0.00      0.00      0.00        30\n","         geo       0.68      0.79      0.73      3087\n","         gpe       0.90      0.91      0.91      1146\n","         nat       0.00      0.00      0.00        16\n","         org       0.35      0.30      0.32      1691\n","         per       0.44      0.53      0.48      1310\n","         tim       0.68      0.69      0.68      1672\n","\n","   micro avg       0.61      0.65      0.63      8989\n","   macro avg       0.38      0.40      0.39      8989\n","weighted avg       0.60      0.65      0.62      8989\n","\n","f1_score improved from 0.000000 to 0.630423, saving model to best_model.h5\n","Epoch 2/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.1639 - acc: 0.9526 - val_loss: 0.1498 - val_acc: 0.9554\n"," - f1: 74.19\n","              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00        37\n","         eve       0.00      0.00      0.00        30\n","         geo       0.75      0.85      0.80      3087\n","         gpe       0.89      0.95      0.92      1146\n","         nat       0.00      0.00      0.00        16\n","         org       0.58      0.47      0.52      1691\n","         per       0.63      0.65      0.64      1310\n","         tim       0.82      0.81      0.81      1672\n","\n","   micro avg       0.74      0.75      0.74      8989\n","   macro avg       0.46      0.47      0.46      8989\n","weighted avg       0.72      0.75      0.73      8989\n","\n","f1_score improved from 0.630423 to 0.741903, saving model to best_model.h5\n","Epoch 3/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.1127 - acc: 0.9659 - val_loss: 0.1411 - val_acc: 0.9577\n"," - f1: 76.09\n","              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00        37\n","         eve       0.00      0.00      0.00        30\n","         geo       0.82      0.83      0.82      3087\n","         gpe       0.90      0.95      0.92      1146\n","         nat       0.00      0.00      0.00        16\n","         org       0.59      0.54      0.57      1691\n","         per       0.65      0.68      0.66      1310\n","         tim       0.83      0.81      0.82      1672\n","\n","   micro avg       0.76      0.76      0.76      8989\n","   macro avg       0.47      0.48      0.47      8989\n","weighted avg       0.75      0.76      0.76      8989\n","\n","f1_score improved from 0.741903 to 0.760894, saving model to best_model.h5\n","Epoch 4/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0920 - acc: 0.9713 - val_loss: 0.1349 - val_acc: 0.9589\n"," - f1: 76.61\n","              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00        37\n","         eve       0.75      0.20      0.32        30\n","         geo       0.80      0.85      0.82      3087\n","         gpe       0.89      0.95      0.92      1146\n","         nat       1.00      0.06      0.12        16\n","         org       0.57      0.57      0.57      1691\n","         per       0.68      0.68      0.68      1310\n","         tim       0.81      0.84      0.83      1672\n","\n","   micro avg       0.76      0.78      0.77      8989\n","   macro avg       0.69      0.52      0.53      8989\n","weighted avg       0.75      0.78      0.76      8989\n","\n","f1_score improved from 0.760894 to 0.766144, saving model to best_model.h5\n","Epoch 5/15\n","34530/34530 [==============================] - 80s 2ms/step - loss: 0.0784 - acc: 0.9752 - val_loss: 0.1381 - val_acc: 0.9588\n"," - f1: 76.92\n","              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00        37\n","         eve       0.55      0.20      0.29        30\n","         geo       0.80      0.86      0.83      3087\n","         gpe       0.91      0.95      0.93      1146\n","         nat       0.75      0.19      0.30        16\n","         org       0.57      0.59      0.58      1691\n","         per       0.66      0.69      0.68      1310\n","         tim       0.82      0.84      0.83      1672\n","\n","   micro avg       0.75      0.78      0.77      8989\n","   macro avg       0.63      0.54      0.55      8989\n","weighted avg       0.75      0.78      0.77      8989\n","\n","f1_score improved from 0.766144 to 0.769164, saving model to best_model.h5\n","Epoch 6/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0688 - acc: 0.9778 - val_loss: 0.1439 - val_acc: 0.9587\n"," - f1: 74.98\n","              precision    recall  f1-score   support\n","\n","         art       0.50      0.11      0.18        37\n","         eve       0.60      0.20      0.30        30\n","         geo       0.78      0.87      0.82      3087\n","         gpe       0.90      0.95      0.92      1146\n","         nat       0.60      0.19      0.29        16\n","         org       0.61      0.56      0.58      1691\n","         per       0.66      0.67      0.67      1310\n","         tim       0.64      0.84      0.73      1672\n","\n","   micro avg       0.72      0.78      0.75      8989\n","   macro avg       0.66      0.55      0.56      8989\n","weighted avg       0.72      0.78      0.75      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 7/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0599 - acc: 0.9805 - val_loss: 0.1521 - val_acc: 0.9580\n"," - f1: 76.26\n","              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00        37\n","         eve       0.55      0.20      0.29        30\n","         geo       0.79      0.86      0.82      3087\n","         gpe       0.90      0.95      0.92      1146\n","         nat       0.86      0.38      0.52        16\n","         org       0.59      0.56      0.57      1691\n","         per       0.68      0.65      0.67      1310\n","         tim       0.78      0.84      0.81      1672\n","\n","   micro avg       0.75      0.78      0.76      8989\n","   macro avg       0.64      0.55      0.58      8989\n","weighted avg       0.74      0.78      0.76      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 8/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0519 - acc: 0.9831 - val_loss: 0.1584 - val_acc: 0.9570\n"," - f1: 74.16\n","              precision    recall  f1-score   support\n","\n","         art       0.50      0.16      0.24        37\n","         eve       0.31      0.13      0.19        30\n","         geo       0.79      0.86      0.82      3087\n","         gpe       0.90      0.94      0.92      1146\n","         nat       0.78      0.44      0.56        16\n","         org       0.57      0.56      0.56      1691\n","         per       0.64      0.67      0.65      1310\n","         tim       0.66      0.83      0.73      1672\n","\n","   micro avg       0.71      0.77      0.74      8989\n","   macro avg       0.64      0.57      0.59      8989\n","weighted avg       0.71      0.77      0.74      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 9/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0454 - acc: 0.9853 - val_loss: 0.1695 - val_acc: 0.9567\n"," - f1: 75.06\n","              precision    recall  f1-score   support\n","\n","         art       0.26      0.16      0.20        37\n","         eve       0.25      0.20      0.22        30\n","         geo       0.81      0.83      0.82      3087\n","         gpe       0.89      0.95      0.92      1146\n","         nat       0.64      0.44      0.52        16\n","         org       0.55      0.59      0.57      1691\n","         per       0.66      0.66      0.66      1310\n","         tim       0.73      0.84      0.78      1672\n","\n","   micro avg       0.73      0.77      0.75      8989\n","   macro avg       0.60      0.58      0.59      8989\n","weighted avg       0.73      0.77      0.75      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 10/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0403 - acc: 0.9870 - val_loss: 0.1785 - val_acc: 0.9547\n"," - f1: 73.22\n","              precision    recall  f1-score   support\n","\n","         art       0.33      0.19      0.24        37\n","         eve       0.26      0.20      0.23        30\n","         geo       0.81      0.82      0.81      3087\n","         gpe       0.90      0.94      0.92      1146\n","         nat       0.55      0.38      0.44        16\n","         org       0.51      0.60      0.55      1691\n","         per       0.65      0.68      0.67      1310\n","         tim       0.64      0.83      0.72      1672\n","\n","   micro avg       0.70      0.77      0.73      8989\n","   macro avg       0.58      0.58      0.57      8989\n","weighted avg       0.71      0.77      0.73      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 11/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0344 - acc: 0.9891 - val_loss: 0.1901 - val_acc: 0.9554\n"," - f1: 68.87\n","              precision    recall  f1-score   support\n","\n","         art       0.22      0.16      0.19        37\n","         eve       0.30      0.23      0.26        30\n","         geo       0.81      0.82      0.81      3087\n","         gpe       0.94      0.94      0.94      1146\n","         nat       0.50      0.75      0.60        16\n","         org       0.56      0.55      0.56      1691\n","         per       0.64      0.71      0.67      1310\n","         tim       0.39      0.84      0.53      1672\n","\n","   micro avg       0.62      0.77      0.69      8989\n","   macro avg       0.55      0.63      0.57      8989\n","weighted avg       0.67      0.77      0.70      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 12/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.2064 - val_acc: 0.9538\n"," - f1: 70.00\n","              precision    recall  f1-score   support\n","\n","         art       0.22      0.16      0.19        37\n","         eve       0.19      0.17      0.18        30\n","         geo       0.79      0.82      0.81      3087\n","         gpe       0.88      0.95      0.91      1146\n","         nat       0.58      0.44      0.50        16\n","         org       0.55      0.55      0.55      1691\n","         per       0.64      0.69      0.66      1310\n","         tim       0.46      0.84      0.59      1672\n","\n","   micro avg       0.65      0.76      0.70      8989\n","   macro avg       0.54      0.58      0.55      8989\n","weighted avg       0.67      0.76      0.71      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 13/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0255 - acc: 0.9920 - val_loss: 0.2142 - val_acc: 0.9533\n"," - f1: 71.11\n","              precision    recall  f1-score   support\n","\n","         art       0.09      0.05      0.07        37\n","         eve       0.21      0.17      0.19        30\n","         geo       0.79      0.82      0.80      3087\n","         gpe       0.90      0.94      0.92      1146\n","         nat       0.59      0.62      0.61        16\n","         org       0.54      0.57      0.55      1691\n","         per       0.66      0.67      0.66      1310\n","         tim       0.52      0.83      0.64      1672\n","\n","   micro avg       0.67      0.76      0.71      8989\n","   macro avg       0.53      0.58      0.55      8989\n","weighted avg       0.68      0.76      0.71      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 14/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0223 - acc: 0.9930 - val_loss: 0.2270 - val_acc: 0.9518\n"," - f1: 70.83\n","              precision    recall  f1-score   support\n","\n","         art       0.07      0.08      0.08        37\n","         eve       0.22      0.17      0.19        30\n","         geo       0.79      0.83      0.81      3087\n","         gpe       0.94      0.94      0.94      1146\n","         nat       0.62      0.62      0.62        16\n","         org       0.51      0.56      0.53      1691\n","         per       0.66      0.66      0.66      1310\n","         tim       0.52      0.82      0.63      1672\n","\n","   micro avg       0.66      0.76      0.71      8989\n","   macro avg       0.54      0.58      0.56      8989\n","weighted avg       0.68      0.76      0.71      8989\n","\n","f1_score did not improve from 0.769164\n","Epoch 15/15\n","34530/34530 [==============================] - 79s 2ms/step - loss: 0.0188 - acc: 0.9943 - val_loss: 0.2431 - val_acc: 0.9530\n"," - f1: 70.21\n","              precision    recall  f1-score   support\n","\n","         art       0.18      0.16      0.17        37\n","         eve       0.21      0.20      0.21        30\n","         geo       0.80      0.81      0.81      3087\n","         gpe       0.94      0.93      0.93      1146\n","         nat       0.67      0.62      0.65        16\n","         org       0.54      0.54      0.54      1691\n","         per       0.63      0.66      0.65      1310\n","         tim       0.48      0.82      0.61      1672\n","\n","   micro avg       0.66      0.75      0.70      8989\n","   macro avg       0.56      0.60      0.57      8989\n","weighted avg       0.68      0.75      0.71      8989\n","\n","f1_score did not improve from 0.769164\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"61VZ295uOENL"},"source":["bilstm_model = load_model('best_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5PAX0JWOEOk","executionInfo":{"status":"ok","timestamp":1611323278319,"user_tz":-540,"elapsed":1750391,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"e44a2a86-39cd-4710-f0e6-0617519fcdcc"},"source":["i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\r\n","y_predicted = bilstm_model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\r\n","y_predicted = np.argmax(y_predicted, axis = -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\r\n","true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\r\n","\r\n","print('{:15}|{:5}|{}'.format('단어', '실제값', '예측값'))\r\n","print(35 * '-')\r\n","\r\n","for w, t, pred in zip(X_test[i], true, y_predicted[0]):\r\n","    if w != 0: # PAD 값은 제외함.\r\n","        print('{:17}: {:7} {}'.format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))\r\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["단어             |실제값  |예측값\n","-----------------------------------\n","the              : O       O\n","statement        : O       O\n","came             : O       O\n","as               : O       O\n","u.n.             : B-org   B-org\n","secretary-general: I-org   I-org\n","kofi             : B-per   B-per\n","annan            : I-per   I-per\n","met              : O       O\n","with             : O       O\n","officials        : O       O\n","in               : O       O\n","amman            : B-geo   B-geo\n","to               : O       O\n","discuss          : O       O\n","wednesday        : B-tim   B-tim\n","'s               : O       O\n","attacks          : O       O\n",".                : O       O\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"09Q80uGrOEQZ"},"source":["f1score = F1score()\r\n","\r\n","y_predicted = bilstm_model.predict([X_test])\r\n","pred_tags = f1score.sequences_to_tags(y_predicted)\r\n","test_tags = f1score.sequences_to_tags(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KiOW-rA6GfuY","executionInfo":{"status":"ok","timestamp":1611323352029,"user_tz":-540,"elapsed":36102,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"443065f2-ebfe-4112-809e-aad4b62ccc62"},"source":["print(classification_report(test_tags, pred_tags))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00        63\n","         eve       0.67      0.04      0.07        52\n","         geo       0.75      0.86      0.80      7620\n","         gpe       0.95      0.93      0.94      3145\n","         nat       0.00      0.00      0.00        37\n","         org       0.62      0.48      0.54      4033\n","         per       0.72      0.72      0.72      3545\n","         tim       0.83      0.82      0.83      4067\n","\n","   micro avg       0.77      0.77      0.77     22562\n","   macro avg       0.57      0.48      0.49     22562\n","weighted avg       0.76      0.77      0.76     22562\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1f32YqKGfxA","executionInfo":{"status":"ok","timestamp":1611323353744,"user_tz":-540,"elapsed":36487,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"f50424dd-8944-43e7-8023-88007b247268"},"source":["print('F1-score : {:.1%}'.format(f1_score(test_tags, pred_tags)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["F1-score : 76.9%\n"],"name":"stdout"}]}]}