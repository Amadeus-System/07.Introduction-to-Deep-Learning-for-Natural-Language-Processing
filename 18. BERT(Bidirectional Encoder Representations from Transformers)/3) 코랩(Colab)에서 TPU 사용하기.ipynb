{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3) 코랩(Colab)에서 TPU 사용하기.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPzta53FURxRZjP7DUVeT3k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"s63Z7aHti5cH"},"source":["## 3) 코랩(Colab)에서 TPU 사용하기\n","\n","지금까지는 GPU 사용만으로도 모델을 학습하는데 큰 무리가 없었지만, BERT의 경우 지금까지 사용한 모델보다 굉장히 무거운 편이다. 그래서 BERT 챕터에서는 가급적 Colab에서 GPU보다 더 빠른 TPU를 사용하여 파인 튜닝을 학습하는 것을 권장한다. 이번 챕터에서는 Colab에서 TPU로 텐서플로우 모델을 학습하는 방법을 알아보자.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JHkNTMGCi_lt"},"source":["### 1.코랩(Colab)에서 TPU를 선택\n","\n","지금까지 Colab에서 GPU를 사용하기 위해서 런타임 유형 변경에서 GPU를 선택했듯이 TPU를 선택한다.\n","\n","* Colab에서 런타임 > 런타임 유형 변경 > 하드웨어 가속기에서 'TPU' 선택\n","\n","GPU를 사용할 때는 런타임 유형 변경에서 GPU를 선택하는 것만으로 GPU를 사용할 수 있었지만, TPU의 경우에는 런타임 유형 변경에서 TPU를 선택한다고 바로 사용할 수 있는 것이 아니다. 아래에서 안내할 추가적인 코드 설정을 해주지 않으면 실제로는 TPU를 사용하지 않게 되므로 아래의 코드 설정을 반드시 해야 한다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"y_e4ctf_i_qF"},"source":["### 2.TPU 초기화\n","\n","딥러닝 모델을 정의하기 전에 아래의 설정을 미리 해주어야 하므로 아래의 코드는 초반부에 실행해준다.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u5z39XIMi_sN","executionInfo":{"status":"ok","timestamp":1616494246870,"user_tz":-540,"elapsed":12607,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"ae4e9ee9-fc47-4f20-96a4-ea55fb81aec9"},"source":["import tensorflow as tf\n","import os\n","\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.70.62.26:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.70.62.26:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.tpu.topology.Topology at 0x7f71b4c2f4d0>"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"Rc3Eo0rki_us"},"source":["### 3.TPU Strategy 셋팅\n","\n","tf.distribute.Strategy는 훈련을 여러 GPU 또는 여러 장비, 여러 TPU로 나누어 처리하기 위한 텐서플로 API이다. 이 API를 사용하면 기존의 모델이나 훈련 코드를 분산처리를 할 수 있다. TPU 사용을 위해서도 Strategy를 셋팅해준다.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jE-99Y99i_w3","executionInfo":{"status":"ok","timestamp":1616494327465,"user_tz":-540,"elapsed":747,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"5a56e09d-b1e6-46e9-b665-067087868813"},"source":["strategy = tf.distribute.TPUStrategy(resolver)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wIyNNhIfi_zC"},"source":["### 4.딥 러닝 모델의 정의\n","\n","딥러닝 모델을 정의할 때도 추가적인 코드가 필요하다. 모델 생성은 strategy.scope 내에서 이루어져야 한다. 이는 모델을 정의하는 create_model()와 같은 함수를 만들어 strategy.scope 내에서 해당 함수를 호출하여 모델을 컴파일하는 방식으로 하면 된다. 예시를 들어보겠다.\n","\n","다음과 같이 임의의 모델을 정의하는 create_model()이라는 함수를 만든다.\n","\n"]},{"cell_type":"code","metadata":{"id":"jFKS_2U9i_1M","executionInfo":{"status":"ok","timestamp":1616494462952,"user_tz":-540,"elapsed":665,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def create_model():\n","  return tf.keras.Sequential(\n","      [tf.keras.layers.Conv2D(256, 3, activation='relu', input_shape=(28, 28, 1)),\n","       tf.keras.layers.Conv2D(256, 3, activation='relu'),\n","       tf.keras.layers.Flatten(),\n","       tf.keras.layers.Dense(256, activation='relu'),\n","       tf.keras.layers.Dense(128, activation='relu'),\n","       tf.keras.layers.Dense(10)])\n","  "],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w7kAN2FDi_3X"},"source":["이제 with strategy.scope(): 다음에 들여쓰기를 하고, create_model() 함수를 호출하고 모델을 컴파일한다. 다시 말해 strategy.scope 내에서 모델이 생성되도록 한다.\n"]},{"cell_type":"code","metadata":{"id":"UuqQgT02i_5h","executionInfo":{"status":"ok","timestamp":1616494579100,"user_tz":-540,"elapsed":1708,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["with strategy.scope():\n","    model = create_model()\n","    model.compile(optimizer = 'adam',\n","                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n","                  metrics = ['sparse_categorical_accuracy'])"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"68cyY143i_8j"},"source":["이제 이 모델을 fit() 하게 되면 해당 모델은 TPU를 사용하게 된다! 앞으로 Colab에서 TPU를 사용하여 BERT 모델을 학습하는 것도 이 과정을 따라서 하게 된다. 위의 1~3번까지의 코드를 실행하고, BERT와 커스텀 레이어에 대한 모델 정의와 컴파일을 strategy.scope 내에서 하면 된다.\n","\n"]}]}