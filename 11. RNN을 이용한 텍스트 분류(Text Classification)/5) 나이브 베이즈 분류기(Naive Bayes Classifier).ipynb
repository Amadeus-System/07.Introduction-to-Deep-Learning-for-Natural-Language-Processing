{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11. RNN을 이용한 텍스트 분류 / 5) 나이브 베이즈 분류기.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMqsfWv9QjEVVustRnTFkN8"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"I6YEFCwzsHe6"},"source":["## 5) 나이브 베이즈 분류기(Naive Bayes Classifier)\r\n","\r\n","텍스트 분류를 위해 전통적으로 사용되는 분류기로 나이브 베이즈 분류기가 있다. 나이브 베이즈 분류기는 인공 신경망 알고리즘에는 속하지 않지만, 머신러닝의 주요 알고리즘으로 분류에 있어 준수한 성능을 보여주는 것으로 알려져 있다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"DyBo6yCvsKbo"},"source":["### 1) 베이즈의 정리(Bayes' theorem)를 이용한 분류 메커니즘\r\n","\r\n","나이브 베이즈 분류기를 이해하기 위해서는 우선 베이즈의 정리(Bayes' theorem)를 이해할 필요가 있다. 베이즈 정리는 조건부 확률을 계산하는 방법 중 하나이다.\r\n","\r\n","$P(A)$가 A가 일어날 확률, $P(B)$가 B가 일어날 확률, $P(B|A)$가 A가 일어나고나서 B가 일어날 확률, $P(A|B)$가 B가 일어나고나서 A가 일어날 확률이라고 해보자. 이때 $P(B|A)$를 쉽게 구할 수 있는 상황이라면, 아래와 같은 식을 통해 $P(A|B)$를 구할 수 있다.\r\n","\r\n","$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$\r\n","\r\n","나이브 베이즈 분류기는 이러한 베이즈 정리를 이용하여 텍스트 분류를 수행한다. 예를 들어서 나이브 베이즈 분류기를 통해서 스팸 메일 필터를 만들어본다고 하자. 입력 텍스트(메일의 본문)이 주어졌을 때, 입력 텍스트가 정상 메일인지 스팸 메일인지 구분하기 위한 확률을 이와 같이 표현할 수 있다.\r\n","\r\n","* **P(정상 메일|입력 텍스트) = 입력 텍스트가 있을 때 정상 메일일 확률**\r\n","* **P(스팸 메일|입력 텍스트) = 입력 텍스트가 있을 때 스팸 메일일 확률**\r\n","\r\n","이를 베이즈의 정리에 따라서 식을 표현하면 이와 같다.\r\n","\r\n","* **P(정상 메일|입력 텍스트) = (P(입력 텍스트|정상 메일) x P(정상 메일)) / P(입력 텍스트)**\r\n","* **P(스팸 메일|입력 텍스트) = (P(입력 텍스트|스팸 메일) x P(스팸 메일)) / P(입력 텍스트)**\r\n","\r\n","입력 텍스트가 주어졌을 때, P(정상 메일|입력 텍스트)가 P(스팸 메일|입력 텍스트)보다 크다면 정상 메일이라고 볼 수 있으며, 그 반대라면 스팸 메일이라고 볼 수 있다. 그런데 두 확률 모두 식을 보면 P(입력 텍스트)를 분모로 하고 있음을 알 수 있다. 그렇기 때문에 분모를 양쪽에서 제거하고 이렇게 식을 간소화할 수 있다.\r\n","\r\n","* **P(정상 메일 | 입력 테스트) = P(입력 테스트 | 정상 메일) × P(정상 메일)**\r\n","* **P(스팸 메일 | 입력 테스트) = P(입력 테스트 | 스팸 메일) × P(스팸 메일)**\r\n","\r\n","입력 텍스트는 메일의 본문을 의미한다고 언급했다. 그런데 메일의 본문을 어떻게 나이브 베이즈 분류기의 입력으로 사용할 수 있을까? 메일의 본문에 있는 모든 단어를 토큰화 시켜서 이 단어들을 나이브 베이즈 분류기의 입력으로 사용한다.\r\n","\r\n","만약 메일의 본문에 있는 단어가 3개라고 가정해보겠다. 기본적으로 나이브 베이즈 분류기는 모든 단어가 독립적이라고 가정한다. 메일의 본문에 있는 단어 3개를 $w_{1}$, $w_{2}$, $w_{3}$라고 표현한다면 결국 나이브 베이즈 분류기의 정상 메일일 확률과 스팸 메일일 확률을 구하는 식은 아래와 같다.\r\n","\r\n","* **P(정상 메일|입력 텍스트) = P($w_{1}$|정상 메일) x P($w_{2}$|정상 메일) x P($w_{3}$|정상 메일) x P(정상 메일)**\r\n","* **P(스팸 메일|입력 텍스트) = P($w_{1}$|스팸 메일) x P($w_{2}$|스팸 메일) x P($w_{3}$|스팸 메일) x P(스팸 메일)**\r\n","\r\n","식을 보고 눈치챈 사람도 있겠지만, 나이브 베이즈 분류기에서 토큰화 이전의 단어의 순서는 중요하지 않다. 즉, BoW와 같이 단어의 순서를 무시하고 오직 빈도수만을 고려한다. 이제 실제 단어들로 이루어진 예제를 통해서 확률을 구해보도록 하겠다.\r\n"]},{"cell_type":"markdown","metadata":{"id":"1aG5f1RisKf4"},"source":["### 2) 스팸 메일 분류기(Spam Detection)\r\n","\r\n","앞서 배운 나이브 베이즈 분류식을 가지고, 입력 텍스트로부터 해당 텍스트가 정상 메일인지 스팸 메일인지를 구분하는 작업을 해보도록 하겠다. 아래와 같은 훈련 데이터가 있다고 가정하겠다.\r\n","\r\n","\r\n","|-\t|메일로부터 토큰화 및 정제 된 단어들\t|분류\r\n","|--|--|--\r\n","|1\t|me free lottery\t|스팸 메일\r\n","|2\t|free get free you\t|스팸 메일\r\n","|3\t|you free scholarship\t|정상 메일\r\n","|4\t|free to contact me\t|정상 메일\r\n","|5\t|you won award\t|정상 메일\r\n","|6\t|you ticket lottery\t|스팸 메일\r\n","\r\n","이때 you free lottery라는 입력 텍스트에 대해서 정상 메일일 확률과 스팸 메일일 확률 각각을 구해보도록 하겠다.\r\n","\r\n","* **P(정상 메일 | 입력 텍스트) = P(you | 정상 메일) × P(free | 정상 메일) × P(lottery | 정상 메일) × P(정상 메일)**\r\n","* **P(스팸 메일 | 입력 텍스트) = P(you | 스팸 메일) × P(free | 스팸 메일) × P(lottery | 스팸 메일) × P(스팸 메일)**\r\n","* **P(정상 메일) = P(스팸 메일) = 총 메일 6개 중 3개 = 0.5**\r\n","\r\n","위 예제에서는 P(정상 메일)과 P(스팸 메일)의 값은 같으므로, 두 식에서 두 개의 확률은 생략이 가능하다.\r\n","\r\n","* **P(정상 메일 | 입력 텍스트) = P(you | 정상 메일) × P(free | 정상 메일) × P(lottery | 정상 메일)**\r\n","* **P(스팸 메일 | 입력 텍스트) = P(you | 스팸 메일) × P(free | 스팸 메일) × P(lottery | 스팸 메일)**\r\n","\r\n","P(you|정상 메일)을 구하는 방법은 정상 메일에 등장한 모든 단어의 빈도 수의 총합을 분모로 하고, 정상 메일에서 you가 총 등장한 빈도의 수를 분자로 하는 것이다. 이 경우에는 2/10 = 0.2가 된다. 이와 같은 원리로 식을 전개하면 다음과 같다.\r\n","\r\n","* **P(정상 메일 | 입력 텍스트) = 2/10 × 2/10 × 0/10 = 0**\r\n","* **P(스팸 메일 | 입력 텍스트) = 2/10 × 3/10 × 2/10 = 0.012**\r\n","\r\n","결과적으로 P(정상 메일|입력 텍스트) < P(스팸 메일|입력 텍스트)이므로 입력 텍스트 you free lottery는 스팸 메일로 분류된다.\r\n","\r\n","그런데 예제를 보니 이상한 점이 보인다. 물론, 직관적으로 보기에도 you, free, lottery라는 단어가 스팸 메일에서 빈도수가 더 높기 때문에 스팸 메일일 확률이 더 높은 것은 확실하다. 그러나 입력 텍스트에 대해서 단, 하나의 단어라도 훈련 텍스트에 없었다면 확률 전체가 0이 되는 것은 지나친 일반화이다. 이 경우에는 정상 메일에 lottery가 단 한 번도 등장하지 않았고, 그 이유로 정상 메일일 확률 자체가 0%가 되어버렸다.\r\n","\r\n","이를 방지하기 위해서 나이브 베이즈 분류기에서는 각 단어에 대한 확률의 분모, 분자에 전부 숫자를 더해서 분자가 0이 되는 것을 방지하는 라플라스 스무딩을 사용하기도 한다.\r\n","\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"7241Rz-DsKjH"},"source":["### 3) 뉴스그룹 데이터 분류하기(Classification of 20 News Group with Naive Bayes Classifier)\r\n","\r\n","사이킷런에서는 Twenty Newsgroups이라고 불리는 20개의 다른 주제를 가진 18,846개의 뉴스그룹 데이터를 제공한다. (토픽 모델링의 LSA 챕터에서 사용했던 데이터와 동일한 데이터) 해당 데이터는 이미 훈련 데이터(11,314개)와 테스트 데이터(7,532개)를 미리 분류해놓았기 때문에 별도로 훈련 데이터와 테스트 데이터를 분류할 필요는 없다. 훈련 데이터로 훈련을 해서 모델을 만들고, 테스트 데이터를 예측했을 때의 정확도를 확인해보도록 하겠다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"21bji2zmsKl5"},"source":["#### (1) 뉴스그룹 데이터에 대한 이해\r\n","\r\n","해당 데이터는 총 6개의 속성을 갖고 있는데, 그 중에서 우리가 사용할 것은 해당 데이터의 본문을 갖고 있는 'data' 속성과 해당 데이터가 어떤 카테고리에 속하는지 0부터 19까지의 라벨이 붙어있는 'target' 속성이 되겠다. 그럼 코드를 보면서 데이터의 구성을 더 구체적으로 알아보도록 하겠다.\r\n","\r\n","우선 훈련 데이터를 다운로드 받아보겠다.\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m76kfCgXsKog","executionInfo":{"status":"ok","timestamp":1610374565554,"user_tz":-540,"elapsed":9693,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"5fca5b09-37ac-48d0-fc47-6cb1528dd09f"},"source":["from sklearn.datasets import fetch_20newsgroups\r\n","newsdata = fetch_20newsgroups(subset = 'train')\r\n","print(newsdata.keys())"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading 20news dataset. This may take a few minutes.\n","Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"],"name":"stderr"},{"output_type":"stream","text":["dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z3I9IjDisKq3"},"source":["위의 코드 부분에 subset 부분에 'all'을 넣으면 18,846개의 전체 데이터를 다운로드할 수 있으며, 'train'을 넣으면 훈련 데이터를, 'test'를 넣으면 테스트 데이터를 다운로드할 수 있다. newsdata.keys()를 출력하여 해당 데이터가 어떤 속성으로 구성되어져 있는지 출력해보았다.\r\n","\r\n","해당 데이터는 data, filenames, target_names, target, DESCR, description이라는 6개 속성의 데이터를 갖고 있다. \r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NXeMwj8msKtI","executionInfo":{"status":"ok","timestamp":1610374729891,"user_tz":-540,"elapsed":984,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"aebd9543-c278-439a-e416-2977c42648fd"},"source":["print(len(newsdata.data), len(newsdata.filenames), len(newsdata.target_names),\r\n","      len(newsdata.target))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["11314 11314 20 11314\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZqKD7Dgc0EmB"},"source":["훈련용 샘플의 개수를 확인해보도록 하겠다.\r\n","\r\n","훈련용 샘플은 총 11,314개로 구성되어 있다. \r\n","\r\n","newsdata.target_names는 이 데이터의 20개의 카테고리의 이름을 담고있다. 어떤 카테고리들로 구성되어 있는지 확인해보도록 하겠다. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tx0iRH6X0TJ0","executionInfo":{"status":"ok","timestamp":1610374797834,"user_tz":-540,"elapsed":1265,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"4cdefed0-5b70-470d-f733-caf740a1a7ce"},"source":["print(newsdata.target_names)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y1gywZLE0VTT"},"source":["target에는 총 0부터 19까지의 숫자가 들어가있는데 첫번째 샘플의 경우에는 몇 번 카테고리인지 확인해보겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbr5WmMQ0dqI","executionInfo":{"status":"ok","timestamp":1610374838996,"user_tz":-540,"elapsed":967,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"486cb464-1d6b-4051-b259-971ed2e1da8e"},"source":["print(newsdata.target[0])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T2w23o5Z0e56"},"source":["첫번째 샘플은 카테고리 7번에 속한다고 라벨이 붙어있다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMfC3ehI0ixn","executionInfo":{"status":"ok","timestamp":1610374859432,"user_tz":-540,"elapsed":1003,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"25dfdc23-0374-4f2d-f106-56b9228ce679"},"source":["print(newsdata.target_names[7])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["rec.autos\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3vB_0yOC0kVA"},"source":["7번 카테고리의 카테고리 제목은 rec.autos이다. 즉, 첫번째 샘플은 rec.autos 카테고리에 속한다. 그렇다면 첫번째 샘플이 어떤 내용을 갖고 있는지 확인해보겠다. \r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBAcLDF-0vlA","executionInfo":{"status":"ok","timestamp":1610374912063,"user_tz":-540,"elapsed":1021,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"f4ff462c-2397-49ef-8a10-e09743d32835"},"source":["print(newsdata.data[0])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["From: lerxst@wam.umd.edu (where's my thing)\n","Subject: WHAT car is this!?\n","Nntp-Posting-Host: rac3.wam.umd.edu\n","Organization: University of Maryland, College Park\n","Lines: 15\n","\n"," I was wondering if anyone out there could enlighten me on this car I saw\n","the other day. It was a 2-door sports car, looked to be from the late 60s/\n","early 70s. It was called a Bricklin. The doors were really small. In addition,\n","the front bumper was separate from the rest of the body. This is \n","all I know. If anyone can tellme a model name, engine specs, years\n","of production, where this car is made, history, or whatever info you\n","have on this funky looking car, please e-mail.\n","\n","Thanks,\n","- IL\n","   ---- brought to you by your neighborhood Lerxst ----\n","\n","\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MQubD-8E0xEY"},"source":["메일의 내용을 보니 스포츠카에 대한 글로 보인다. 즉, 이 스포츠카에 대한 글은 총 0부터 19까지의 카테고리 중 7번 레이블에 속하는 글이고, 7번은 rec.autos 카테고리를 의미한다는 것을 알 수 있다. \r\n"]},{"cell_type":"markdown","metadata":{"id":"lmwQ8dZv1A4f"},"source":["#### (2) 나이브 베이즈 분류\r\n","\r\n","이제 다운로드 받은 훈련 데이터에 대한 전처리를 진행해보겠다. 사용할 데이터는 newsdata.data와 그에 대한 카테고리 레이블이 되어있는 newsdata.target이라고 언급한 바 있다. 여기서 전처리를 해야하는 데이터는 newsdata.data이다. 위에서 보았듯이 해당 데이터는 토큰화가 전혀 되어있지 않다. 나이브 베이즈 분류를 위해서는 데이터를 BoW로 만들어줄 필요가 있다.\r\n","\r\n","여기서는 입력한 텍스트를 자동으로 BoW로 만드는 CountVectorizer를 사용한다. (BoW 챕터 및 DTM 챕터 참고)\r\n"]},{"cell_type":"code","metadata":{"id":"LMClIDEu1BVR","executionInfo":{"status":"ok","timestamp":1610375151192,"user_tz":-540,"elapsed":922,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["from sklearn.feature_extraction.text import CountVectorizer\r\n","from sklearn.feature_extraction.text import TfidfTransformer\r\n","from sklearn.naive_bayes import MultinomialNB # 다항분포 나이브 베이즈 모델\r\n","from sklearn.metrics import accuracy_score # 정확도 계산"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_wu9MUZ1BYO","executionInfo":{"status":"ok","timestamp":1610375187063,"user_tz":-540,"elapsed":4007,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"0445982f-0bff-4afa-d9ff-25757696a28e"},"source":["dtmvector = CountVectorizer()\r\n","X_train_dtm = dtmvector.fit_transform(newsdata.data)\r\n","print(X_train_dtm.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(11314, 130107)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wwpqo3DP1BbL"},"source":["이제 자동으로 DTM이 완성되었다. 11,314는 훈련용 샘플의 개수이고 DTM 관점에서는 문서의 수가 되겠다. 130,107은 전체 훈련 데이터에 등장한 단어의 수를 의미한다.\r\n","\r\n","물론, DTM을 그대로 나이브 베이즈 분류기에 사용할 수도 있겠지만 DTM 행렬 대신 TF-IDF 가중치를 적용한 TF-IDF 행렬을 입력으로 텍스트 분류를 수행하면, 성능의 개선을 얻을 수도 있다. (DTM 챕터 참고) 주의할 점은 TF-IDF 행렬이 항상 DTM으로 수행했을 때보다 성능이 뛰어나지는 않다는 것이다. 사이킷런은 TF-IDF를 자동 계산해주는 TfidVectorizer 클래스를 제공하므로 이를 사용해보겠다.\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjG-o_vS1BdY","executionInfo":{"status":"ok","timestamp":1610379645900,"user_tz":-540,"elapsed":941,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"1c00f485-3861-4113-d62c-16c79ad2b1d5"},"source":["tfidf_transformer = TfidfTransformer()\r\n","tfidfv = tfidf_transformer.fit_transform(X_train_dtm)\r\n","print(tfidfv.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(11314, 130107)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pSPjXouL1Bfk"},"source":["이제 TF-IDF 행렬이 만들어졌다. 이제 본격적으로 나이브 베이즈 분류를 수행해보도록 하겠다. 사이킷런은 나이브 베이즈 모델을 지원하므로, 이를 그대로 갖고와서 사용하겠다.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsV9wgHN1BiZ","executionInfo":{"status":"ok","timestamp":1610379713422,"user_tz":-540,"elapsed":954,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"32fad10d-e798-4a6e-bae6-e45de1924b03"},"source":["mod = MultinomialNB()\r\n","mod.fit(tfidfv, newsdata.target)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"xOiiIffJ1BkT"},"source":["모델의 입력으로 TF-IDF 행렬과 11,314개의 훈련 데이터에 대한 레이블이 적혀있는 newsdata.target이 들어간다. 이는 앞서 배운 분류 예제들을 상기해보면, 각각 X_train과 y_train에 해당되는 데이터들이다.\r\n","\r\n","위에서 alpha = 1.0은 라플라스 스무딩이 적용되었음을 의미한다.\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCDQ-pOt1Bm_","executionInfo":{"status":"ok","timestamp":1610380049408,"user_tz":-540,"elapsed":3098,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"73b2d155-fc7f-4dcd-ea12-99afaf46357d"},"source":["newsdata_test = fetch_20newsgroups(subset = 'test', shuffle = True) # 테스트 데이터 갖고오기\r\n","X_test_dtm = dtmvector.transform(newsdata_test.data) # 테스트 데이터를 DTM으로 변환\r\n","tfidfv_test = tfidf_transformer.transform(X_test_dtm) # DTM을 TF-IDF 행렬로 변환\r\n","\r\n","predicted = mod.predict(tfidfv_test) # 테스트 데이터에 대한 예측\r\n","print('정확도:', accuracy_score(newsdata_test.target, predicted)) # 예측값과 실제값 비교\r\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["정확도: 0.7738980350504514\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mqxbk1Vb1BpZ"},"source":["77%의 정확도를 얻었다. 여기서는 하지 않았지만, 잠재 의미 분석 챕터에서 진행했던 전처리를 모두 진행하고 다시 나이브 베이즈 분류기를 돌려보아라. 80% 이상의 정확도를 얻을 수 있다.\r\n","\r\n"]}]}